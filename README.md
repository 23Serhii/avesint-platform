AVESINT.AI — README по всьому проєкту (актуально)
Додатково: PROJECT_ANALYSIS.md — стислий технічний огляд; OSINT_PIPELINE.md — конвеєр збору/верифікації даних; SYSTEM_MODULES.md — детальний опис усіх модулів системи.

Що це:
- Військова OSINT-платформа для моніторингу подій, верифікації даних та аналітики в реальному часі.
- Монорепозиторій зі SPA-клієнтом (React), бекенд‑API (NestJS) та воркером для асинхронних задач.

Технологічний стек (фактична реалізація)
- Frontend: React 19, Vite 7, TypeScript, Tailwind CSS, @tanstack/react-router; UI-компоненти на базі shadcn/ui.
- Backend API: NestJS 11, TypeORM, PostgreSQL, Socket.IO (WebSocket), class-validator/-transformer.
- Background worker: osint-worker (Node/TypeScript) — парсинг/OSINT, черги та фонові задачі.

Структура репозиторію
- avesint-ai-client — SPA клієнт.
- avesint-ai-server/api — NestJS API сервер.
- osint-worker — фоновий воркер для збору/обробки даних (за потреби запускати окремо).
- docker-compose.yml — швидкий старт інфраструктури (PostgreSQL, за потреби інші сервіси).
- PROJECT_ANALYSIS.md, OSINT_PIPELINE.md — додаткові матеріали.

Ключові можливості (фічі)
- Стрічка подій і AI‑Stream: агрегований потік IntelligenceItem (події/новини/OSINT) з фільтрами часу, типу, статусу, джерела.
- Інтерактивна мапа подій: геовідображення з панеллю бокової навігації та деталями.
- Верифікація: підтвердження/спростування, статуси, журнал аудиту.
- Аналітика/дашборд: графіки подій, розподіли, тренди.
- Аутентифікація та роли: JWT, guard’и ролей, захищені маршрути.
- WebSocket оновлення: миттєві апдейти через Socket.IO.

Швидкий старт (локальна розробка)
1) Вимоги: Node 18+, pnpm, Docker (за бажанням), PostgreSQL (локально або через docker-compose).
2) Підняти інфраструктуру (опційно):
   - docker-compose up -d  (підніме БД PostgreSQL, якщо налаштовано в файлі)
3) Налаштувати бекенд (avesint-ai-server/api/.env):
   - DB_HOST, DB_PORT, DB_USER, DB_PASS, DB_NAME
   - DB_SYNCHRONIZE=true  (лише для dev)
   - CORS_ORIGINS=http://localhost:5173 (список через кому дозволених origin)
   - JWT_SECRET=...  (секрет для підпису токенів)
4) Запустити API:
   - cd avesint-ai-server/api && pnpm i && pnpm start:dev
   - API за адресою: http://localhost:3000/api
5) Запустити клієнт:
   - cd avesint-ai-client && pnpm i && pnpm dev
   - SPA за адресою: http://localhost:5173

Основні модулі бекенда (NestJS)
- Auth: JWT‑логін, DTO LoginDto, декоратор @Roles(), guards для доступу.
- Events: CRUD подій, геокоординати, пошук/фільтри, пагінація.
- Osint: модуль інтеграцій/парсерів OSINT, підготовка даних до стрічки.
- Tasks: асинхронні задачі/черги (планування, обробка воркером).
- AI Stream (ai-stream): контролер для агрегованого потоку /api/stream, нормалізований DTO IntelligenceItem.
- Common: декоратори/утиліти (наприклад, roles.decorator.ts), глобальні пайпи, інтерсептори.

Основні можливості клієнта (React SPA)
- Маршрутизація: @tanstack/react-router (файлові маршрути; приклад: /_authenticated/map/ — карта подій).
- UI: shadcn/ui + Tailwind, теми (ThemeSwitch), профіль (ProfileDropdown), Drawer конфігурації.
- Події: список/карта, панель подій (EventsMapViewport, EventsMapSidebar), посторінкове завантаження.
- Пошук: глобальний компонент Search, фільтри на сторінках.
- Аналітика: DashboardEventsChart, DashboardEventsPie, Tasks тощо.
- API клієнт: /src/lib/api/* (включно з stream.ts для стріму агрегованих елементів).

API огляд (вибірково)
- POST /api/auth/login — повертає JWT (payload: JwtPayloadInterface).
- GET  /api/events — список подій (параметри page, pageSize, фільтри).
- GET  /api/stream — агрегований список IntelligenceItem (Events/News/OSINT) з пагінацією.
- WebSocket (Socket.IO) — канал оновлень подій/стріму в реальному часі (за токеном).

Змінні середовища (основні)
- API (avesint-ai-server/api/.env): DB_HOST, DB_PORT, DB_USER, DB_PASS, DB_NAME, DB_SYNCHRONIZE, CORS_ORIGINS, JWT_SECRET.
- Client (avesint-ai-client/.env): VITE_API_BASE_URL=http://localhost:3000/api, інші VITE_*

Скрипти (pnpm)
- Клієнт: pnpm dev, pnpm build, pnpm preview, pnpm lint, pnpm typecheck.
- API: pnpm start:dev, pnpm build, pnpm start:prod, pnpm lint.
- Воркер: pnpm start:dev (у каталозі osint-worker, якщо застосовується).

Безпека та доступ
- CORS: контролюється CORS_ORIGINS (перелік origin через кому).
- Roles/guards: доступ до ендпоінтів обмежується декоратором @Roles() + guard.
- JWT: підпис токенів через JWT_SECRET; зберігання токена на клієнті — у пам’яті/secure‑storage.

Тестування та якість
- Юніт/інтеграційні тести можуть бути додані в API та клієнті (vitest/jest). Рекомендовано покриття критичних модулів (auth/events/stream).
- TypeScript strict і ESLint правила — для стабільності й консистентності коду.

Відомі маршрути інтерфейсу (приклади)
- /login — вхід, UserAuthForm.
- /dashboard — дашборд показників та задач.
- /_authenticated/map — інтерактивна карта подій (EventsMapViewport + EventsMapSidebar).
- /review — верифікація/огляд підозрілих елементів (може бути представленням фільтрів стріму).

Поради з деплою (коротко)
- PROD: DB_SYNCHRONIZE=false, міграції обов’язково; CORS_ORIGINS вказати потрібні домени; JWT_SECRET обов’язково кастомний.
- Реверс‑проксі (nginx/caddy) для API та SPA; ввімкнути HTTPS і wss.
- Горизонтальне масштабування WS через sticky‑sessions або Redis adapter для Socket.IO.

План еволюції UI (узагальнено)
- Єдина стрічка (Stream) з пресетами: «Verification Queue», «OSINT Findings», «Events Only».
- Уніфіковані компоненти: ItemRow/Card, ConfidenceMeter, SourceBadge, ItemActions.

Чекліст мінімальних робіт (стан)
- [x] /api/stream (read‑only агрегат) + базова сторінка стріму на клієнті.
- [ ] Preset «Verification Queue» у стрімі.
- [ ] Уніфікація UI‑компонентів для всіх типів елементів.

Де шукати деталі у коді
- Клієнт: src/features/*, src/routes/*, src/lib/api/*
- API: src/auth/*, src/events/*, src/osint/*, src/ai-stream/*, src/common/*
- Приклад: Events мапа — src/routes/_authenticated/map/index.tsx та src/features/events/components/*

Примітки
- Цей README узагальнює актуальний стан реалізації. Нижче йде історичне детальне ТЗ, яке може частково не збігатися зі стеком і використовується як референс вимог.

Нижче — оригінальне детальне ТЗ (історичний документ; може містити невідповідності до поточного стеку, лишено як довідник вимог):

Проектна Документація та Технічне Завдання
1. Вступ
   AVESINT.AI – це військова OSINT-платформа (розвідка з відкритих джерел), призначена виключно для використання військовими фахівцями (без залучення волонтерів). Метою платформи є надання інструментарію для оперативного збору, перевірки та аналізу інформації з відкритих джерел у режимі реального часу, що сприятиме ситуаційній обізнаності командування та підрозділів.
   Головні завдання платформи:
   •	Моніторинг поточних подій (бойові дії, інциденти, загрози) на інтерактивній карті та у стрічці новин у режимі реального часу.
   •	Автоматизований аналіз даних за допомогою вбудованого AI-агента: перевірка достовірності інформації, оцінка надійності джерел, виконання OSINT-запитів щодо об’єктів (особи, судна, літальні апарати, джерела).
   •	Забезпечення механізму людської верифікації: можливість фахівцю вручну підтвердити або спростувати інформацію з обґрунтуванням та посиланням на джерело.
   •	Накопичення аналітики по джерелах (історія повідомлень, рейтинги достовірності) та повна історія подій (інцидентів), розслідувань і перевірок.
   •	Звітування: генерація звітів за подіями або періодами (наприклад, добових зведень) з можливістю налаштування формату для подальшого використання керівництвом.
   •	Забезпечення безпеки та контролю доступу на рівні, відповідному військовим стандартам (авторизація, ролі, 2FA, аудиту дій).
   Документ структуровано як технічне завдання (ТЗ) для внутрішнього використання командою розробки. У ньому детально описано функціональні модулі, архітектуру системи, структуру даних, механіки роботи окремих компонентів, сценарії використання, технологічний стек, вимоги безпеки, а також наведено план реалізації (MVP – мінімально життєздатний продукт протягом ~1 місяця) з пріоритетами.
2. Огляд системи
   2.1 Основні можливості та модулі
   Платформа AVESINT.AI складається з низки інтегрованих модулів, що забезпечують повний цикл роботи з OSINT-даними – від збору та обробки інформації до її верифікації та представлення кінцевому користувачу. Нижче наведено ключові модулі системи:
   •	Головний інтерфейс (дашборд): реального часу стрічка подій, інтерактивна карта з позначенням інцидентів, останні новини та тривожні сповіщення.
   •	AI-агент: підсистема штучного інтелекту для автоматичного опрацювання запитів, перевірки фактів, розрахунку коефіцієнтів достовірності та запуску OSINT-розвідки по заданих об’єктах.
   •	Модуль верифікації (Validation): інтерфейс та логіка для ручного підтвердження або спростування інформації аналітиками-людьми з фіксацією джерел доказів.
   •	Аналітика джерел: окремий розділ, де зібрана статистика по кожному інформаційному джерелу (історія повідомлень, успішність/помилки, поточний рейтинг надійності, можливість додати/видалити джерело тощо).
   •	Інтерактивна карта подій: геопросторова візуалізація усіх зареєстрованих подій з можливістю фільтрації за типом, часом, достовірністю, географією та іншими параметрами.
   •	Адмін-панель (панель керування): розширені можливості адміністрування – керування базою даних (словники об’єктів, списки джерел), управління користувачами та їхніми ролями, налаштування системи та AI-модуля.
   •	Система звітності: генерація різних видів звітів (за окремою подією, добові зведення, аналітичні довідки) з опціями форматування та експорту (PDF, DOCX, CSV тощо).
   •	Журнал подій та розслідувань: повна історія всіх інцидентів, здійснених розслідувань, прийнятих рішень щодо достовірності даних, дії користувачів (audit log).
   2.2 Загальна архітектура
   Архітектурно AVESINT.AI побудована за принципом клієнт-серверної веб-платформи:
   •	Front-end: односторінковий веб-додаток (SPA) на Angular, що забезпечує інтерактивний інтерфейс користувача. На фронтенді реалізовано відображення карти (Google Maps API чи OpenStreetMap + Leaflet), стрічки подій, форм для введення запитів до AI, інтерфейс верифікації та всі адмін-сторінки. Обмін даними з сервером здійснюється через HTTPS (REST API) та WebSocket для миттєвих оновлень.
   •	Back-end: серверна частина на Go (Golang), що відповідає за бізнес-логіку, обробку даних та інтеграцію з БД і зовнішніми сервісами. Go обрано через його продуктивність та можливість ефективної роботи з конкурентними завданнями (обробка паралельних потоків подій в реальному часі). Сервер надає RESTful API для CRUD-операцій (отримання подій, джерел, тощо) та окремий WebSocket-ендпойнт для push-нотифікацій (нові події, оновлення).
   •	База даних: PostgreSQL як основна реляційна БД для збереження структурованих даних (події, джерела, користувачі, інциденти тощо). Використання PostgreSQL забезпечує надійність зберігання, можливості складних SQL-запитів та розширення PostGIS для геоданих (координати подій). Також застосовується Redis для кешування часто використовуваних даних та реалізації механізмів публікації/підписки (pub/sub) для оперативної доставки повідомлень про нові події на фронтенд через WebSocket.
   •	AI/LLM-сервіс: компонент, інтегрований із зовнішнім API (наприклад, OpenAI API) або розгорнутою локально великою мовною моделлю (LLM) для виконання інтелектуальних функцій. Цей сервіс може бути викликаний бекендом для обробки запитів користувача (напряму чи через чергу завдань). Для чутливих даних військового характеру бажано передбачити можливість використання локальної LLM (запущеної на захищеному сервері), щоб уникнути передачі інформації третім сторонам.
   •	Зовнішні інтеграції: у разі потреби система може звертатися до зовнішніх OSINT-джерел через API або веб-скрапінг – наприклад, до відкритих API соціальних мереж, сервісів моніторингу судноплавства (AIS), авіаційного трекінгу (ADS-B), баз даних осіб (реєстрів, санкційних списків тощо) та новинних агрегаторів. Для модуля парсингу новин передбачено окремий скрипт або сервіс, що виконується за розкладом чи вручну.
   Примітка з безпеки: Вся комунікація між компонентами відбувається по захищених каналах. Web-додаток працює виключно через HTTPS. WebSocket сполучення захищене (wss://) і вимагає дійсного токена сесії. Дані в БД шифруються на рівні диску, а конфіденційні поля (наприклад, паролі, токени доступу) зберігаються у хешованому/зашифрованому вигляді.
   2.3 Ключові сценарії використання
   •	Моніторинг бойової ситуації в реальному часі: Аналітик відкриває дашборд AVESINT.AI і бачить стрічку подій (наприклад, повідомлення про авіаудар, переміщення техніки, повітряну тривогу тощо) та карту з геоприв’язаними маркерами цих подій. Система автоматично оновлює ці дані в реальному часі (без необхідності ручного перезавантаження сторінки) – нові події «пушаться» через WebSocket. При тривалій неактивності оператора платформа може показати спливаюче вікно з переліком останніх важливих подій, щоб швидко зорієнтувати по оновленнях.
   •	Перевірка отриманого повідомлення: При появі нової події AI-агент автоматично присвоює їй початковий коефіцієнт достовірності, аналізуючи інформацію (текст, медіа) та джерело. Аналітик бачить, що, наприклад, подія має достовірність 0.6 (60%) і позначена як “непідтверджена”. Він відкриває деталі події, переглядає рекомендації AI щодо верифікації (наприклад, список знайдених схожих повідомлень, попередження про можливий фейк, пропозиції джерел для перехресної перевірки) та вирішує провести ручну перевірку. Через інтерфейс верифікації він додає посилання на офіційне підтвердження (або спростування) і змінює статус події на “підтверджено” (або “спростовано”). Система зберігає, хто і коли зробив цю дію, оновлює коефіцієнт достовірності (до 0.95, наприклад, якщо підтверджено) і відображає це всім користувачам.
   •	OSINT-розвідка по об’єкту: Розвідник отримав завдання з’ясувати інформацію про певне судно (корабель або літак) або особу. Він відкриває вкладку “Огляд” або спеціальний інтерфейс AI-агента та вводить запит природною мовою, наприклад: “Виконай OSINT-розвідку щодо судна з бортовим номером XYZ123 (ймовірно, військовий корабель)”. AI-агент приймає запит, запускає відповідні методи (наприклад, шукає згадки про цей бортовий номер у відкритих базах AIS/ADS-B, новинах, соцмережах), аналізує зібрані дані і видає звіт користувачу: історія переміщень судна, порт приписки, останні новини, пов’язані з ним, тощо. Якщо деякі кроки потребують доступу до закритих API, агент формує запит, щоб оператор міг вручну завантажити ці дані або підтвердити використання наявних інтеграцій.
   •	Генерація добового звіту: Наприкінці дня черговий аналітик відкриває модуль “Звіти” і запускає формування добового зведення. Система автоматично збирає всі підтверджені події за останні 24 години, групує їх за категоріями (наприклад, авіаудари, бойові зіткнення, переміщення військ, інформаційні операції), додає основні метрики (кількість подій, розподіл по регіонах, рівень достовірності) та генерує документ у обраному форматі (PDF). Перед фіналізацією звіту користувач може вручну відкоригувати або доповнити текст, скориставшись підказками AI для формулювання висновків. Готовий звіт зберігається в системі і може бути завантажений або надісланий командуванню.
   •	Додавання нового джерела інформації: Адміністратор виявив новий телеграм-канал, який регулярно публікує цінні розвіддані. Через панель керування він відкриває розділ “Джерела” і додає нове джерело, вказавши його тип (Telegram), ім’я та URL API/фіда. Система автоматично передає цей ресурс AI-агенту для первинної оцінки: агент завантажує останні пости з каналу, аналізує зміст на наявність корисної інформації та встановлює початковий коефіцієнт достовірності (наприклад, 0.8 на основі історичних даних, якщо більшість постів підтверджені іншими джерелами). Після цього новий канал інтегровано: парсер новин відслідковує його повідомлення, а події з нього надходять у стрічку з відповідною поміткою.
   Далі у документі детально описано кожен модуль та механізм реалізації, з технічними деталями та вимогами.
3. Функціональні вимоги
   3.1 Реал-тайм оновлення інформації (Головний інтерфейс)
   Головна сторінка платформи AVESINT.AI являє собою оперативний дашборд з кількома ключовими компонентами:
   •	Стрічка подій – хронологічний перелік останніх зареєстрованих подій. Для кожної події відображаються короткі відомості: час, заголовок/тип події, локація, джерело(а) інформації, поточний статус достовірності (наприклад, іконка або колір, що позначає “підтверджено / непідтверджено / спростовано”, а також числовий коефіцієнт надійності, напр. 0.7). Стрічка оновлюється в реальному часі завдяки WebSocket: при надходженні нової події або зміні статусу існуючої, відповідний елемент динамічно додається або оновлюється без перезавантаження сторінки. Користувач може прокручувати стрічку, фільтрувати події за категоріями (тип події, регіон, рівень достовірності) або шукати по ключових словах.
   •	Карта – інтерактивна географічна карта, на якій відображаються події у вигляді маркерів. Кожен маркер відповідає конкретній події з прив’язкою до координат (якщо подія має геолокацію). Колір або форма маркера може відображати тип події (наприклад, червоні вибухи, сині переміщення військ, жовті попередження тощо) та/або рівень підтвердженості (наприклад, заповнений кружок для підтверджених, порожній – для непідтверджених). При наведенні чи кліку на маркер показується попап з короткою інформацією (аналогічно рядку у стрічці) та посиланням на деталі події. Карта підтримує фільтри (можна включати/відключати відображення окремих типів подій, показувати лише події з високою достовірністю, вибирати часовий проміжок) та масштабування. Реалізація на Angular може використовувати бібліотеки на зразок Leaflet чи Google Maps API. Сервер надає API для отримання списку подій у певних координатних межах або навколо поточного центру карти для оптимізації (щоб не завантажувати всі події разом).
   •	Розділ новин – у правій або нижній частині дашборду може бути відображена стрічка останніх новин (з вибраних офіційних або якісних медіа) або окремий віджет тривог (наприклад, “Повітряна тривога” по регіонах). Ці дані також оновлюються в реальному часі: наприклад, підключення через WebSocket до каналу оповіщень про повітряну тривогу, щоб миттєво відобразити сигнал на екрані. Вкладка “Новини” також доступна як окрема сторінка/вкладка, про що детальніше у розділі 3.10.
   •	Сповіщення про неактивність – якщо користувач тривалий час (наприклад, 10 хвилин) не виконує дій в інтерфейсі, система може показати спливаюче вікно з переліком X останніх важливих подій, які сталися за цей час. Це дозволить швидко зорієнтуватися, не переглядаючи всю стрічку. Критерії “важливості” можуть визначатися типом події (наприклад, обстріли, авіація – завжди вважаються важливими) або високим коефіцієнтом достовірності + підтвердженням.
   Технологічні аспекти реалізації реального часу:
   З боку бекенду використовується WebSocket (або технологія Server-Sent Events) для широкомовного надсилання оновлень. Наприклад, нова подія, що зберігається в БД, публікується на Redis-канал “events:new”, а всі підключені фронтенд-клієнти (підписані на оновлення) одержують повідомлення з даними події у форматі JSON. Angular-клієнт отримує це через сервіс WebSocket і оновлює модель даних, що автоматично відображається в UI (використовуючи RxJS для потоків даних). Аналогічно, при зміні статусу події (верифікація) або інших оновленнях – надсилаються повідомлення “events:update”. Система спроектована так, щоб витримувати одночасне підключення багатьох користувачів без втрати продуктивності; для цього бекенд може використовувати ефективну реалізацію неблокуючих WebSocket (пакет net/http у Go з горутинами), а Redis Pub/Sub забезпечує масштабування на декілька інстансів серверу.
   3.2 AI-агент та його можливості
   AI-агент в AVESINT.AI – це інтегрований модуль штучного інтелекту, який базується на технологіях великих мовних моделей (GPT-4, Llama 2 тощо) і допоміжних скриптів для OSINT. Його функції діляться на кілька категорій:
   3.2.1 Виконання завдань від користувача
   AI-агент надає інтерфейс (чат-бот або спеціальну форму), де авторизований користувач може поставити довільне завдання в природній мовіі. Наприклад: “Знайди всі доступні дані про особу [ПІБ] із відкритих джерел” або “Підготуй стислий аналіз подій за останню годину в секторі Б”. Агент аналізує запит і вирішує, які інструменти чи дані задіяти:
   •	Якщо завдання вимагає пошуку інформації у відкритому інтернеті, агент може згенерувати відповідний пошуковий запит (Google Dork, запит до спеціалізованих OSINT-інструментів) і виконати веб-скрапінг результатів. Примітка: З міркувань безпеки прямий доступ агента до інтернету може бути обмежений або проходити через перевірені проксі/сервіси, щоб уникнути витоку інформації. Для MVP можливо використання API пошукових систем (наприклад, сервіси типу SerpAPI) або інтеграція з вже наявними OSINT-базами.
   •	Якщо завдання стосується аналізу внутрішніх даних, агент звертається до бази даних платформи. Наприклад, на запит "покажи всі інциденти за участю 3-ї бригади за останній тиждень" – виконується SQL-запит по таблиці подій/інцидентів та формується відповідь.
   •	Якщо завдання потребує генерації тексту, резюме, перекладу або структурування інформації – LLM використовується для синтезу відповіді. Агент отримує потрібні факти (з БД чи зовнішніх джерел), а потім просить мовну модель згенерувати зв’язну відповідь українською мовою.
   •	У разі складних многоетапних завдань, агент може виконувати їх ітеративно, повідомляючи користувача про хід роботи (наприклад: "1) Завантажую дані з реєстрів... 2) Аналізую соціальні профілі... 3) Формую звіт...").
   Взаємодія з користувачем: Результати роботи AI-агента відображаються або в чат-інтерфейсі (діалог, де запит і відповідь зберігаються, як у логі), або в окремих модулях (напр., генерація звіту автоматично відкриває модуль "Звіти" з попередньо заповненим документом). Користувач може задати уточнюючі питання до відповіді AI чи попросити додаткові деталі, використовуючи контекст діалогу.
   3.2.2 Автоматична перевірка (верифікація) інформації
   Одна з ключових функцій AI-агента – автономна перевірка нових повідомлень. Коли система отримує нову подію (наприклад, парсер знайшов повідомлення про вибух в певному місті), AI-агент автоматично:
   •	Перевіряє наявність інших джерел цієї ж інформації. Агент шукає схожі повідомлення: проглядає стрічки інших надійних джерел, соцмережі, офіційні заяви. Якщо знаходить підтвердження в декількох незалежних джерелах – впевненість в події зростає[1]. Наприклад, якщо і Twitter, і офіційний сайт містять дані про той самий інцидент, це суттєво підвищує достовірність. Відомо, що найкращою практикою OSINT є перехресна перевірка: звірка інформації з декількома незалежними джерелами та перевірка цифрових слідів (час/місце створення фото чи відео тощо)[1]. Агент намагається застосувати ці принципи автоматично.
   •	Переглядає контент на ознаки фейку або маніпуляції. Наприклад, якщо є зображення чи відео, агент (при наявності відповідних моделей) виконує аналіз метаданих, пошук зображення в інтернеті (reverse image search) для визначення, чи не старе це фото, чи не було воно згенероване. Також лінгвістичний аналіз тексту може допомогти знайти ознаки ботів або пропаганди (надмірно емоційна лексика, невідповідність фактів).
   •	Оцінює надійність першоджерела. Якщо подія надійшла від певного джерела, агент враховує його історичний рейтинг (див. розділ 3.4) та тип: офіційне джерело, відоме ЗМІ чи новостворений анонімний телеграм-канал. Першому автоматично можна давати вищу довіру, другому – меншу.
   •	Присвоює початковий коефіцієнт достовірності. Виходячи з перевірок вище, агент розраховує числовий показник (0.0 – абсолютно недостовірно, 1.0 – повністю підтверджено). Алгоритм може бути, наприклад, на основі вагових коефіцієнтів: база (рейтинг джерела) * поправочні коефіцієнти (наявність підтверджень з інших джерел, результати аналізу контенту). Якщо інформація не підтверджена більше ніким, крім маловідомого джерела – може бути виставлено ~0.3. Якщо багато підтверджень і надійні джерела – ~0.8 або вище.
   •	Рекомендації для аналітика. Агент може додати до події внутрішній коментар: наприклад, “Знайдено 3 схожих повідомлення від [Джерело A] і [Джерело B]”, або “Метадані фото вказують, що зображення зроблено 2 дні тому за координатами..., можливий фейк”. Ці нотатки допоможуть людині швидше прийняти рішення.
   В результаті цих дій кожна нова подія одразу має статус (наприклад, “не підтверджено, достовірність 0.5, AI Verified”) у стрічці, привертаючи увагу аналітиків до потенційно важливих, але ще неперевірених даних.
   Система може працювати подібно до підходу Liveuamap: агрегувати повідомлення і пропонувати людині підтвердити – коли накопичується багато корельованих повідомлень про подію, вона виноситься на розгляд операторам[2]. У Liveuamap поріг спрацьовує і щонайменше двоє модераторів вирішують, чи подія підтверджена й буде нанесена на мапу[3]. За аналогією, AVESINT.AI при високому коефіцієнті достовірності може автоматично позначати подію як “попередньо підтверджена” і виводити нотифікацію для чергових аналітиків про необхідність верифікації. Надалі, зворотний зв’язок (manual validation) використовується для донавчання моделі: якщо агент часто помилявся з певним джерелом чи типом подій, ці знання враховуються (можливо, через оновлення параметрів або просто як дані в БД, які агент перевіряє перед оцінкою).
   3.2.3 Оцінка достовірності джерел і подій (коефіцієнт цілісності)
   Як згадано, в системі застосовується коефіцієнт достовірності (інтегральний показник, “коефіцієнт цілісності”) – числова міра, що відображає наскільки можна довіряти інформації або джерелу. AI-агент відіграє роль у розрахунку та актуалізації цих коефіцієнтів:
   •	Для джерел: Платформа веде для кожного джерела історію публікацій та їх статус. На основі цього розраховується рейтинг (наприклад, частка достовірних повідомлень). Формула може бути: рейтинг = (підтверджені повідомлення + 0.5 * спростовані) / загальна кількість, або більш складна з урахуванням давності (нові помилки впливають сильніше ніж старі). AI-агент може оновлювати цей рейтинг після кожного нового підтвердження/спростування, або періодично. Також можливе використання шкали на основі модифікованого коду Адміралтейства (Admiralty Code), прийнятого в розвідці: наприклад, джерелу присвоюється літера A (надійне) до F (ненадійне)[4][5], а інформації – цифра 1 (підтверджена) до 6 (неправдива). У нашій реалізації зручніше мати континуальну шкалу 0..1, але при бажанні можна додати відображення у вигляді літер/оцінок.
   •	Для подій: Коефіцієнт для кожної події змінюється протягом її “життєвого циклу”. Спочатку – значення, розраховане AI (як описано вище). Потім, якщо люди підтверджують чи спростовують подію, коефіцієнт коригується стрибкоподібно (до 1.0 або 0.0 в ідеалі). Проте, навіть підтверджена подія може мати проміжне значення, якщо, наприклад, є деталі які ще уточнюються. Агент може повторно аналізувати подію, якщо з’являються нові дані: наприклад, перерахувати достовірність з урахуванням щойно знайденого відео.
   •	Відображення: Користувачі бачать ці коефіцієнти у UI у вигляді відсотків або шкали. Наприклад, біля назви джерела – зелена іконка 0.9 (90% надійності), біля події – жовтий індикатор ~0.5. В аналітичному модулі при перегляді джерела можна побачити графік зміни його рейтингу з часом.
   AI-агент допомагає автоматизувати обчислення та може давати пояснення: якщо рейтинг джерела впав, агент може позначити “після 3 випадків публікації непідтверджених новин рейтинг знизився”. Це стимулює прозорість і довіру до системи з боку користувачів.
   3.2.4 Автоматизована OSINT-розвідка (особи, судна, джерела)
   Особливий режим роботи AI-агента – глибинний OSINT-пошук за заданими об’єктами:
   •	По особах: При запиті щодо фізичної особи (наприклад, ім’я, позивний, аккаунт соцмережі) агент використовує комбінацію технік: пошук у відкритих реєстрах (судові, бізнес-реєстри, витоки даних), соцмережах, Google. Якщо доступні профілі – збирає інформацію (фото, біографічні дані, зв’язки). Може використати інструменти розпізнавання облич (для перевірки чи різні фото належать одній людині). Результат – структуроване досьє: ПІБ, дата народження (якщо знайдено), ролі (військовий, чиновник тощо), згадки в новинах, соціальні зв’язки. Безпека: такі розвідзапити виконуються тільки уповноваженими користувачами з відповідною роллю (наприклад, “OSINT-офіцер”), і логуються ретельно (щоб уникнути зловживань).
   •	По суднах/літальних апаратах: Агент має доступ до баз, як-от MarineTraffic (для кораблів) чи ADS-B Exchange (для літаків), якщо не прямий, то через отримані дані. За бортовим номером чи назвою судна можна отримати тип (танкер, фрегат, борт ВПС тощо), країну реєстрації, останню відому позицію, маршрут. Агент також перевіряє новини щодо цього судна: чи фігурувало воно в інцидентах (наприклад, затримано, помічено біля берегів України і т.д.). Результат – звіт про судно: технічні характеристики, поточний статус, історія подій за участю нього.
   •	По джерелах: Наприклад, розвідка “хто стоїть за цим телеграм-каналом”. Агент аналізує метадані джерела: дату створення, приблизну аудиторію, тематику дописів. Шукає, чи згадувався автор каналу десь, чи пов’язаний з іншими ресурсами. Може визначити мову, стиль, активність за часом (для припущень, з якого часового поясу автор). Якщо джерело – сайт, збирає whois, дані про хостинг. Це допомагає оцінити, чи не є джерело підставним/ворожим.
   •	Додаткові OSINT-інструменти: У платформі можуть бути інтегровані сторонні інструменти (напр. Maltego, Shodan, Skopenow тощо[6][7]) через API. Агент може запускати їх у фоні та інтерпретувати результат. Наприклад, для кіберрозвідки може використовувати Shodan (скан відкритих пристроїв), для соцмереж – відповідні API.
   Результати розвідки відображаються у зручному форматі: або як сторінка профілю об’єкта (з вкладками “Основне”, “Активність”, “Пов’язані події”), або як звіт у форматі тексту з заголовками. Користувач може зберегти отриману інформацію до бази даних (наприклад, створити картку нової особи чи судна на основі знайденого).
   Примітка: AI-агент не надає інформацію з закритих джерел чи те, що виходить за рамки OSINT. Він лише автоматизує і прискорює збір відкритих даних. Також він виконує роль помічника, але остаточне рішення (наприклад, про висновки з розвідки) приймає людина.
   3.3 Механізм ручної валідації (верифікації) інформації
   Жоден автоматичний алгоритм не може гарантувати повну достовірність усього OSINT-матеріалу, тому AVESINT.AI передбачає механізм людської верифікації кожної події. Суть його полягає в тому, що військовий аналітик (користувач з відповідними правами) переглядає нові події та позначає їх статус на основі власної перевірки:
   •	Статуси подій: “Підтверджено”, “Спростовано”, “В очікуванні”. За замовчуванням нові події мають статус “В очікуванні підтвердження” (або аналогічний ярлик). Аналітик може змінити статус на “Підтверджено” (якщо знайдено надійне підтвердження – офіційний прес-реліз, відео з геолокацією, яке співпадає з подією і т.д.) або “Спростовано” (якщо виявлено, що інформація неправдива – наприклад, виявлено, що фото старе, або офіційні особи заперечили факт події).
   •	Інтерфейс підтвердження: При відкритті детальної картки події, доступна кнопка/меню “Верифікувати”. Натиснувши, користувач бачить форму з опціями: вибрати новий статус, додати коментар та додати посилання на джерело підтвердження/спростування. Джерелом може бути URL новини, архів соцмереж, знімок екрану, файл – усе, що служить доказом. Це посилання обов’язкове, щоб зберігати прозорість і можливість аудиту: кожна зміна статусу підтверджується конкретним доказом.
   •	Прив’язка до користувача: Система зберігає, який користувач (логін/ім’я) і коли встановив статус. Ця інформація відображається іншим (наприклад, “Підтверджено користувачем <u123> 14.10.2025 13:45, джерело: link”). У випадку помилки її можна буде простежити і, при потребі, відкликати.
   •	Можливість перегляду історії змін: Якщо статус змінювався кілька разів (скажімо, спочатку підтвердили, потім з’явилася інформація про помилку і статус змінили на спростовано) – у картці події доступний повний лог: хто які дії виконав, з відповідними мітками часу.
   Алгоритм дій аналітика для верифікації:
1.	Виявлення події. Аналітик бачить нову подію у стрічці з позначкою “в очікуванні”. За пріоритетністю він обирає найбільш критичні (напр. з великою потенційною важливістю чи високою недостовірністю).
2.	Перевірка джерел. Він може вручну переглянути першоджерело (наприклад, перейти на пост у соцмережі), оцінити його. Система може надати допоміжну кнопку “Відкрити всі згадки”, яка збирає посилання на знайдені AI схожі повідомлення.
3.	Пошук підтверджень. Аналітик шукає підтвердження: перевіряє офіційні канали, зв’язується з колегами у полі (якщо є така можливість), аналізує медіа (через інструменти платформи або зовнішні, наприклад перевіряє EXIF фото).
4.	Виставлення рішення. Якщо подія підтверджується – обирає статус “Підтверджено”, додає посилання (наприклад, на офіційний зведення Генштабу, де згадується цей інцидент) і зберігає. Якщо спростовується – аналогічно, “Спростовано”, посилання (наприклад, аналіз Bellingcat, що це старе фото, або заява МО, що інформація не відповідає дійсності).
5.	Наслідки для системи. Збереження змін:
6.	Коефіцієнт достовірності події виставляється на 1.0 або 0.0 (можливо, 0.99 і 0.01 для уникнення ідеальних абсолютів) та позначається як “людськи підтверджено” або “спростовано”.
7.	Для джерела, яке надало цю інформацію, оновлюється статистика: +1 до підтверджених повідомлень (або +1 до хибних). Це вплине на його рейтинг.
8.	AI-агент може отримати сигнал про цю дію, щоб оновити свої моделі. Наприклад, якщо він раніше вважав джерело досить надійним, але люди часто спростовують інформацію з нього – агент перегляне рейтинг джерела.
9.	Іншим користувачам, які онлайн, приходить оновлення (через WebSocket) про зміну статусу. На карті, якщо подія була відображена, маркер змінює вигляд (наприклад, стає яскравішим), а в стрічці запис пересувається (можливо, підтверджені події сортуються вище, або виділяються).
      Вкладка “Рев’ю (Адмін)”: у лівій навігації згадується вкладка “Рев’ю (Адмін)” – імовірно, це розділ де адміністратори або старші аналітики переглядають список подій, які очікують підтвердження. Там може бути зведена таблиця: подія, час, джерело, поточний AI-рейтинг, скільки вже джерел знайдено, хто взяв в роботу тощо. Це полегшує розподіл роботи між командою. За бажанням, можна реалізувати механізм “взяти подію в роботу” – щоб не дублювати зусилля, аналітик “закріпляє” на собою подію під час верифікації.
      3.4 Аналітика по джерелах
      Модуль аналітики джерел покликаний надати повний огляд та керування усіма джерелами інформації, що використовуються в системі. Це включає соціальні медіа-акаунти, телеграм-канали, сайти новин, офіційні сторінки держорганів, громадські організації і т.д. Функціонал модулю:
      •	Перелік джерел: Сторінка зі списком усіх внесених в систему джерел. Для кожного відображається: назва, тип (категорія), поточний коефіцієнт достовірності (рейтинг), кількість повідомлень з нього в системі, частка підтверджених/спростованих, дата останньої активності (останнього отриманого повідомлення). Таблицю можна сортувати за будь-яким зі стовпців (наприклад, вивести спочатку найнадійніші джерела, чи навпаки, ті, що часто помиляються).
      •	Фільтри: Можна відфільтрувати за типом (наприклад, показати тільки “соцмережі” або тільки “офіційні сайти”), за статусом (наприклад, виділити джерела з рейтингом нижче 0.5 – кандидати на виключення), за активністю (н-д, джерела, що не постили нічого >1 місяця).
      •	Детальна сторінка джерела: При виборі конкретного джерела відкривається його “профіль”. Тут містяться:
      •	Основна інформація: назва, опис, посилання/ідентифікатор (URL чи @username), тип, відповідальний куратор (можливо, хто додав це джерело), поле для приміток.
      •	Історія повідомлень: список або графік кількості повідомлень з цього джерела по днях. Можна відкрити хронологію останніх, кожен запис клікабельний (веде на відповідну подію в системі). Також підсумки: всього подій, з них підтверджено X (Y%), спростовано Z (W%), в очікуванні N.
      •	Коефіцієнт достовірності: поточне значення (0-1 або в процентах). Можливо, варто відображати й “рівень довіри” в якісній шкалі, наприклад: >0.9 – “Висока надійність”, 0.7-0.9 – “В загальному надійне”, 0.4-0.7 – “Сумнівне”, <0.4 – “Ненадійне”. Формула обчислення може бути гнучко налаштовувана. На екрані показується: “Рейтинг рахується як: (підтв. повідомлень + 0.5*непідтв.)/всього. Останній перегляд: 14.10.2025 12:00”. При необхідності адміністратор може вручну відкоригувати рейтинг (наприклад, якщо є стороння інформація, що джерело стало ненадійним, навіть якщо в нас ще статистика невелика).
      •	Графік/історія рейтингу: Лінійний графік зміни рейтингу з часом або принаймні лог змін (дати, події, що вплинули).
      •	Додаткові дані: Якщо відомо, хто веде це джерело або звідки воно (напр. “неофіційний канал Повітряних Сил ЗСУ”), це зазначається. Можна інтегрувати простий knowledge graph – зв’язки джерела з іншими (наприклад, “адміністратор цього телеграм-каналу – такий-то користувач Twitter” якщо відомо).
      •	Додавання нового джерела вручну: Через цю ж вкладку (або через Адмін-панель) користувач з правами Адміна може додати нове джерело:
      •	Натискає кнопку “Додати джерело”.
      •	Заповнює форму: назва, тип (випадаючий список: Twitter, Telegram, Web, etc.), URL або унікальний ідентифікатор (наприклад, для Telegram – назва або ID каналу, для Twitter – ім’я користувача чи ID), категорія (опціонально: наприклад, “Офіційне Міністерство”, “Волонтер”, “Пропагандистський канал” – ці категорії потрібні для фільтрації), мова (укр/англ/рос тощо).
      •	Після збереження система створює запис у БД з статусом “неперевірено”.
      •	AI-агент інтеграції джерела: одразу ж (або за розкладом, але краще одразу) агент починає процедуру інтеграції: підключається до API чи скрапінгом отримує останні, скажімо, 10-20 повідомлень цього джерела. Аналізує їх на зміст (про що вони), чи немає очевидного спаму, оцінює стиль (наприклад, якщо це Telegram – чи не бот, якщо Twitter – чи давно створений акаунт, скільки підписників). На основі цього:
      o	Якщо джерело активне і виглядає релевантним – помічає як “активне, розпочато трекінг”. Коефіцієнт надійності може бути спочатку встановлений середній (0.5) або, якщо є якісь дані (наприклад, з 10 постів 8 виявились потім правдою за нашою базою) – розрахований.
      o	Якщо джерело не відповідає (наприклад, невірний URL чи приватний канал) – система повідомить про помилку (“не вдалося підключитись”).
      o	Якщо джерело вочевидь нерелевантне або суто пропагандистське – агент може попередити (“Виявлено ознаки пропаганди, рейтинг встановлено низький 0.2. Перевірте доцільність додавання цього джерела.”). Остаточне рішення лишається за людиною – залишити чи видалити.
      •	Після цієї автоматичної оцінки адміністратор бачить нове джерело в списку, може вручну скорегувати його дані чи рейтинг якщо потрібно.
      •	Редагування/видалення джерела: передбачено можливість відключити джерело (щоб парсер його більше не збирав) або видалити (але видалення зазвичай не рекомендується, адже тоді історичні події втратять посилання на джерело; краще помічати як “деактивовано”). Також можна відредагувати назву, категорію або інші поля, якщо змінилися.
      •	Пошук по джерелах: Вбудований пошук дозволяє знайти джерело за назвою чи URL. Це зручно, якщо база велика (сотні джерел).
      Пріоритети реалізації для MVP: Базово необхідно реалізувати додавання/видалення джерел і відображення ключових статистик. Графіки та складні алгоритми рейтингу можуть бути дороблені поступово. Головне – щоб система одразу враховувала статистику підтверджень/спростувань для наступних розрахунків.
      3.5 Візуалізація подій на мапі
      Інтерактивна мапа – центральний елемент, що дозволяє сприймати ситуацію просторово. Її функціонал:
      •	Відображення подій: Кожна подія, що має географічні координати (широту/довготу), відображається на карті маркером. Якщо координати не задані явно, але є назва населеного пункту або області – система може здійснити геокодування (наприклад, використати API карт, щоб отримати координати міста) і поставити маркер приблизно в центрі того нас.пункту. Події без геоприв’язки (наприклад, суто кібер-інциденти або аналітичні новини) на карті не показуються, але можуть бути доступні через стрічку.
      •	Кластеризація: При великій кількості маркерів в одній області карта може групувати їх в кластери (кола з цифрою). При наближенні (zoom in) кластери розпадаються на окремі події.
      •	Колірна диференціація: Маркери можуть бути різного кольору або форми. Наприклад:
      •	Червоний вибух – бойове зіткнення, обстріл.
      •	Помаранчевий трикутник – попередження/тривога.
      •	Синій значок танка – переміщення техніки.
      •	Білий значок камери – верифіковані фото/відео локації.
      •	Сірий значок питання – подія з сумнівною достовірністю.
      Можна використовувати готові набори іконок або SVG для динамічної генерації (із числовим показником вбудованим, але це складніше). У легенді карти (кут екрану) наводиться пояснення значків та кольорів. - Фільтри та шари: - Тип події: чекбокси для вибору: військові (бойові) дії, цивільні інциденти, інформаційні операції, тощо – користувач може залишити тільки потрібні. - Рівень достовірності: повзунок або декілька опцій (показувати все, лише підтверджені >0.8, >0.5). Це дозволить сховати “шум”. - Часовий фільтр: наприклад, слайдер чи поля дати/часу – показати події тільки за останні 24 години, або за обраний день. На карті можуть бути сотні точок за місяці, тому корисно обмежувати. - Географічний: якщо платформа покриває велику територію (світ, країну) – можна мати випадачку "Регіон" (наприклад, Україна, Близький Схід, світ) яка фільтрує події в межах. - Шари: окрім подій, на карті можуть бути додаткові шари – наприклад, шар “лінія фронту” (який може оновлюватися вручну), зони контролю, або території повітряних тривог. Ці шари адміністратор може завантажувати у форматі GeoJSON або малювати вручну через інструмент на мапі. Для MVP, ймовірно, достатньо простої статичної карти без складних шарів, але передбачити їх структуру варто.
      •	Взаємодія з подією через карту: Клік на маркер відкриває невеличкий попап: в ньому коротко – назва події, час, джерело, достовірність. Можна натиснути “Детальніше”, що або відкриє бічну панель з детальною інформацією, або перекине на сторінку стрічки до цього елементу (проскролить і виділить його). Також, можливо, прямо з попапу будуть кнопки “Підтвердити”/“Спростувати” (для тих, у кого є права), щоб швидко не переходячи між вкладками підтверджувати події.
      •	Оновлення в реальному часі: Так само як стрічка, карта повинна оновлюватися при надходженні нових даних. Це може реалізовуватися двома шляхами:
      •	Через те саме повідомлення WebSocket – фронт додає маркер на карту.
      •	Або шляхом періодичного опитування стану (не бажано, але якщо WS випав, тоді fallback).
      Так чи інакше, при будь-яких оновленнях (новий маркер, зміна кольору маркера через підтвердження) – користувач бачить це одразу. Можливо, для акценту новий маркер може підсвічуватись анімацією (коротке миготіння). - Масштаб і зона видимості: Якщо події відбуваються по всій країні, користувач може панорамувати карту. Коли він зміщує або змінює масштаб, фронтенд може завантажувати тільки події в межах видимого вікна (т.з. bounding box), звертаючись до API. Це оптимізує кількість даних. Реалізація: Angular отримує події з беку з параметрами ?lat1,lon1,lat2,lon2 – координати кутів карти. - Навігація по карті: Можна передбачити можливість знайти локацію: поле пошуку населеного пункту, або кнопки швидкого переходу (наприклад, “Київ”, “Донецька обл.”). Також якщо в стрічці обрати подію, карта автоматично фокусується на ній (і навпаки – обрати маркер виділяє подію в стрічці, якщо відкрита). - Мобільний/масштаб: Врахуємо, що платформа може використовуватись на планшетах. Дизайн карти повинен бути адаптивним (або окрема сторінка карти, яка розгортається на весь екран мобільного). Але основний фокус – десктоп використання.
      Мап-сервіс: Для MVP можна використати безкоштовні варіанти: - OpenStreetMap + Leaflet (потрібно хостити тайли або використовувати готові, з врахуванням ліцензії). - Mapbox (безкоштовно з певними обмеженнями). - Google Maps (потребує API ключа, можливі платні ліміти).
      Враховуючи військовий характер (можливо, обмеження інтернет доступу), краще мати офлайн-карти – згенеровані тайли OSM, збережені на сервері (або хоча б кешовані найбільш важливі масштаби по зоні конфлікту). Це дозволить працювати при відсутності зовнішнього інтернету (в закритому контурі, якщо таке буде) – хоча тоді й OSINT-дані отримувати важче, такий сценарій теж розглядається.
      3.6 Інтерактивна панель керування (Admin Panel)
      Панель адміністрування доступна користувачам з роллю Адміністратор (див. 3.7). Вона надає інтерфейс для налаштування системи та моніторингу її стану:
      •	Моніторинг системи: Розділ, де відображаються технічні показники: кількість отриманих подій за сьогодні, за останню годину; кількість активних WebSocket-підключень; використання пам’яті сервером, стан черг завдань AI (скільки запитів обробляється), і т.д. Це допоможе адміну розуміти навантаження і вчасно реагувати, якщо щось зависло (наприклад, черга парсингу).
      •	Керування джерелами: Дублюється описаний вище модуль (3.4) або інтегрується сюди. Адміністратор може додавати/видаляти джерела, переглядати їх статистику, змінювати налаштування парсингу (наприклад, частоту).
      •	Керування БД та словниками:
      •	Таблиці довідників: можливо, є таблиці “типи подій”, “категорії джерел”, “типи користувачів” тощо – їх значення можна редагувати безпосередньо тут (CRUD простий).
      •	Об’єкти розвідки: перегляд та редагування записів в таблицях persons, vessels і incidents. Наприклад, адміністратор може вручну створити запис “Інцидент: Операція у м.Х” і прив’язати до нього ряд подій, об’єднавши їх в одну справу. Або додати нового “Персона” (наприклад, ворожого командира) в базу навіть до того, як AI збере про нього дані – щоб мати заготовку.
      •	Журнали (логи): доступ до журналу дій користувачів (хто логінився коли, хто що підтвердив, додав і т.д.). Тут важлива безпека: такі логи тільки для старших адміністраторів.
      •	Налаштування AI: Параметри, що стосуються AI-модулю:
      •	API-ключі для OpenAI чи інших сервісів (з можливістю їх оновлення; ключі зберігаються зашифровано).
      •	Вибір режиму роботи AI: “хмарний GPT-4” чи “локальний LLM” (якщо є).
      •	Ліміти: наприклад, максимальна кількість одночасних AI-запитів, чи обмеження довжини відповідей (щоб випадково не вивів секретні дані, що малоймовірно, але).
      •	Модерація контенту AI: якщо використовується OpenAI, можливо підключена їхня content filter. Військова тематика часом підпадає під політики, але у нас це потрібно – тож адмін може відключити фільтрацію або тонко налаштувати (якщо є така опція).
      •	Оновлення моделей: якщо локальна модель, то завантаження/заміна файлів, якщо хмарна – версія моделі.
      •	Налаштування системи:
      •	Користувацькі параметри: session timeout (30 хв зараз), політика паролів, чи обов’язкове 2FA, строки згод (банер “секретно” чи інше).
      •	Інтерфейс: можливо, тексти інтерфейсу, локалізація (але наразі все укр).
      •	Безпека: можливість тимчасово ввімкнути режим підвищеної безпеки, напр. обмежити вхід нових користувачів, або переключити систему в offline-режим (не тягнути дані з інтернету) – такі функції можуть бути корисні при навчаннях чи загрозах (але це далеко не MVP-шні, скоріше future).
      •	Керування користувачами/ролями: (Також винесено окремо в 3.7) – зазвичай, адмін-панель містить UI для створення нових облікових записів, блокування, скидання паролів, тощо.
      •	Парсер новин: Вкладка “Новини/Парсер” (згадана як окрема в навігації) також може бути частиною адмін-панелі. В ній:
      •	Список джерел, з яких парситься інформація (RSS-стрічки, сайти).
      •	Кнопка “Запустити парсинг зараз” – ручний запуск. При натисканні відповідний скрипт починає збирати свіжі новини (напр., останні 10 новин з кожного джерела) і додавати як події або як записи в розділ новин.
      •	Налаштування розкладу: наприклад, за замовчуванням парсер працює кожні 15 хвилин. Можна змінити цей інтервал.
      •	Журнал парсингу: коли останній раз виконувався, скільки новин додано, чи були помилки.
      Парсинг новин: Для MVP достатньо підтримати RSS/Atom фіди (багато сайтів новин їх мають). У БД буде таблиця news_sources (можна об’єднати з загальними sources, просто з прапором “news”), де для кожного джерела зберігається URL фіду і шаблони парсингу (якщо потрібно). Якщо фіду немає – можна використовувати бібліотеки-скрапер (наприклад, на Go: Colly, на Python (якщо окремо) – BeautifulSoup). Але бажано уникати складних HTML-скрапінгів у MVP, сконцентруватись на тих, де можна щось взяти легко.
      Після збору новин, кожна новина може: - Або створювати нову подію (якщо це релевантно). Наприклад, новина “Ворог обстріляв позиції ...” – це подія типу “обстріл”. AI-агент навіть може парсити текст новини і заповнювати поля події: що сталося, де, коли (найчастіше час – “сьогодні вранці” – можна поставити поточну дату). - Або зберігатися окремо в розділі новин, не як подія (особливо якщо це аналітична стаття). Проте, враховуючи специфіку, напевно краще конвертувати всі короткі новини у події, а довгі статті можна ігнорувати або зберігати просто для читання.
      Адмін-панель повинна бути захищена належним чином: наприклад, додатковим підтвердженням дії (confirm dialog) при видаленні даних, щоб випадково не стерти джерело або користувача.
      3.7 Керування користувачами та ролями
      Оскільки платформа використовується тільки військовими фахівцями, коло користувачів обмежене, і кожен мусить мати аккаунт з відповідною роллю. Вимоги до системи управління користувачами:
      •	Реєстрація/додавання користувачів: публічної реєстрації немає (тільки адмін може додати нового користувача, або імпортувати список). При створенні акаунта задаються: ім’я користувача (логін), ПІБ або позивний (для відображення), роль, можливі налаштування 2FA (наприклад, прив’язаний номер телефону чи email для підтверджень), початковий пароль (який потім можна примусово змінити при першому вході). Також можна додати атрибути як-от підрозділ, посада – для внутрішнього обліку.
      •	Аутентифікація (Login): вхід по логіну/паролю + якщо ввімкнено, другий фактор. Паролі зберігаються у БД у вигляді хешів (алгоритм Argon2id чи PBKDF2 з сіллю). 2FA реалізується через:
      •	TOTP (Time-based One-Time Password): користувач генерує QR-код у профілі, додає до додатку (Google Authenticator або MIL-specific) і при вході вводить код.
      •	Або SMS/E-mail OTP: менш бажано, але можна підтримати відправку одноразового коду.
      У MVP можна почати з TOTP (як найпоширенішого і offline-методу). - Авторизація (Roles & Permissions): В системі визначаємо ролі, наприклад: - Admin (Адміністратор): повний доступ до усіх налаштувань, може додавати користувачів, джерела, бачить тех.панель. - Analyst (Аналітик): основний користувач, який може переглядати все, змінювати статуси подій (верифікувати), генерувати звіти, робити OSINT-запити. Не має доступу до адміністрування користувачів чи системних налаштувань. - Viewer (Спостерігач): можливо роль з правами лише читання: може дивитись стрічку, карту, звіти, але не може підтверджувати події чи робити запити до AI. (Ця роль, наприклад, для тих, хто просто отримує інформацію, але не редагує). - OSINT Operator: можливо окрема роль для тих, хто може робити розвідзапити по особах/суднах, якщо хочемо обмежити (але можна і дозволити всім аналітикам).
      Ролі та їх права можна зафіксувати в коді або зробити налаштовуваними (таблиця permissions). На етапі MVP достатньо трьох ролей з жорстко заданими правами. - Безпека сесій: Після успішного входу користувач отримує JWT токен або сесійний cookie. Використаємо сучасний підхід: JWT access token (дійсний короткий час, скажімо 15 хв) + refresh token (живет на клієнті, в HttpOnly cookie, чи localStorage, для оновлення сесії до 30 хв). Так, session timeout 30 хв – означає, що якщо 30 хв немає активності, сесія закінчується і потрібно заново логінитися. Реалізація: бекенд відслідковує останню активність (можна в JWT в payload класти час останньої дії, або на сервері тримати таблицю активних сесій), і якщо refresh запит приходить пізніше ніж 30 хв від останньої, не продовжувати. - Вихід (Logout): Кнопка виходу, яка інвалідую токени (можна зберігати refresh tokens in blacklist or as DB entry with status). - Захист від несанкціонованого доступу: Всі API-ендпоїнти перевіряють токен та ролі. Додатково, щоб запобігти brute-force паролів, можна реалізувати rate limiting або captcha після N невдалих спроб входу. - Password policy: Воєнна безпека вимагає складних паролів. Мінімум: 12 символів, верхній/нижній регістр, цифри, спецсимволи. Паролі з минулих витоків – заборонити (можна інтегрувати API типу HaveIBeenPwned offline чек). Також регулярна ротація паролів (наприклад, раз на 90 днів) – це опційно, бо 2FA вже покращує безпеку. - Аудит користувачів: Кожна важлива дія користувача (вхід, спроба з неправильним паролем, зміна пароля, ввімкнення 2FA, редагування даних, дії в системі як верифікація події) – логуються. Ці журнали доступні адміну (як згадано). - Session management: якщо один і той же користувач може бути залогінений з декількох пристроїв – варто відображати йому список активних сесій у профілі (наприклад, “Web, IP адреса, остання активність, кнопка Вийти”). При підозрі, він може завершити інші сесії. - Timeout warning: за 5 хв до автоматичного виходу можна показати користувачу попередження з таймером та кнопкою “Продовжити сесію”, що викликає refresh.
      Реалізація на практиці: використовуємо бібліотеки JWT для Go (напр., golang-jwt) та middleware для Angular (перехоплювач HTTP, що додає Authorization header і обробляє 401, пробуючи refresh).
      3.8 Створення звітів
      Модуль звітів дозволяє формувати підсумкові документи на основі даних, що є в системі. Передбачені декілька видів та форматів:
      •	Звіт за подією (інцидентом): користувач може на базі однієї події або групи подій створити міні-звіт. Наприклад, сталася значуща подія (великий бій) – потрібно підготувати інформаційну довідку. В інтерфейсі події додається опція “Згенерувати звіт”. За натиском:
      •	Система відкриває редактор звіту, куди підставляє основну інформацію: заголовок (автоматично – тип події і місце, але можна редагувати), час, місце, учасники (якщо визначені), достовірність. Додає текст опису (якщо він був, наприклад з новин) і список джерел.
      •	AI-агент може доповнити текст: пропонує короткий виклад (summary) з акцентом на ключові факти.
      •	Користувач дописує/редагує текст, може додати зображення (наприклад, докласти карту або фото, якщо доступні), таблиці.
      •	Після цього зберігає звіт. Він може бути збережений як запис у БД (таблиця reports) та/або одразу експортований.
      •	Експорт: MVP-варіант – згенерувати PDF. Можна використати бібліотеки типу ReportLab (Python) або gofpdf (Go). Або більш гнучко: сформувати HTML шаблон і конвертувати через headless browser (Puppeteer). Додатково дозволити зберегти як DOCX, XLS (для структурованих даних) – ці формати можна пізніше додати.
      •	Добовий зведений звіт: Спеціальний вид, який охоплює великий проміжок часу (зазвичай 24 години). Він формується або вручну (користувач обирає “Створити добовий звіт за <дату>”) або автоматично (по розкладу, наприклад щодня о 20:00 готується шаблон, який аналітик лише перевіряє і затверджує).
      •	Зміст такого звіту: кількість подій за добу, перелік найбільш важливих (зазвичай підтверджених) з коротким описом, статистика по типам (наприклад, обстрілів стільки-то, диверсій стільки-то), можливо, карта з відмітками всіх подій дня.
      •	AI може виконати великий обсяг: згрупувати події за темами (“Протягом дня продовжувалися бої на таких-то напрямках, найбільш інтенсивно...”), підсумувати. Людина перевіряє і виправляє.
      •	Форматування: добовий звіт, як правило, багатосторінковий текст + таблиці + зображення (наприклад, карта операцій). Тому генерація PDF тут актуальна. Також бажано мати варіант DOCX, щоб за потреби вручну щось додати вже після експорту.
      •	Шаблонізація: Платформа може мати шаблони для таких регулярних звітів, щоб підтримувати єдиний стиль. Адмін може редагувати шаблон (наприклад, титульна сторінка, стандартні розділи).
      •	Кастомні звіти: Користувач може створити звіт довільного формату, наприклад, за вибраний період або тему. Для цього – опція “Новий звіт”. У ній:
      •	Форма вибору параметрів: період (дати “з – по”), фільтри (по регіону, по типу подій, по джерелу тощо), чи включати карту/графіки.
      •	Після вибору – знов-таки генерується чорновик, який можна редагувати.
      •	Приклад: “Звіт по діяльності Чорноморського флоту РФ за жовтень” – аналітик задає 1-31 жовтня, тип подій: військово-морські, джерела: вибирає кілька ключових, і система витягає всі релевантні події, групує їх, AI пише огляд (“У жовтні спостерігалося збільшення активності...”), додає графік кількості виходів кораблів по днях (якщо є дані). Це досить просунуто, але AI з даними може допомогти.
      •	Збереження та каталог звітів: Усі створені звіти зберігаються і доступні у розділі “Звіти”. Там буде список із назвами, датами створення, автором, типом (подієвий, добовий, кастомний). Можна відкрити для перегляду (HTML-версія) або завантажити. Можливе позначення статусу звіту: чернетка / фінал / відправлено.
      •	Обмін звітами: Платформа може дозволяти надіслати звіт електронною поштою чи інтеграцію з месенджером (але військові навряд чи будуть відправляти через публічні сервіси). Тому, мінімально – завантажують PDF і далі вже власними засобами передають.
      •	Безпека звітів: Оскільки звіти можуть містити важливі висновки, доступ до них теж регулюється ролями. Наприклад, Viewer може взагалі не бачити неопубліковані звіти або бачити тільки фінальні зведення.
      3.9 Історія інцидентів, розслідувань і верифікацій
      Платформа зберігає повну історію всіх об’єктів та дій для забезпечення аудиту і аналізу минулих подій:
      •	Інциденти та розслідування: поняття “інцидент” можна трактувати як значуща подія або група подій, що об’єднані сценарієм. Наприклад, інцидент “Атака на базу X” може включати кілька подій: “Безпілотник помічено...”, “Вибухи на базі...”, “Офіційне підтвердження атаки...”. Система повинна дозволяти групувати події в інциденти. Це може бути:
      •	Автоматично: AI-агент за схожістю місця/часу/учасників може пропонувати “Ці 3 події є частиною одного інциденту”.
      •	Вручну: аналітик обирає “Об’єднати в інцидент” і створює або вибирає існуючий.
      Історія інцидентів – це фактично журнал усіх таких значущих випадків. В окремій вкладці можна переглядати список інцидентів (назва, дата, статус вирішення якщо актуально). Наприклад, якщо інцидент – розслідування теракту, він може мати стан “в процесі” або “завершено”. - Розслідування: близьке до інциденту поняття, але більше відноситься до процесу. Коли аналітики здійснюють OSINT-розвідку (особливо глибоку по особах чи подіях), це можна оформити як “розслідування” з власним ID. У рамках розслідування можуть накопичуватися ноти, проміжні знахідки. Система може зберігати лог: хто і що шукав, які проміжні висновки зробив (наприклад, якщо аналітик вручну вводить примітки). Це корисно при передачі справ між змінами або наверх – видно хід думок і дій. У журнал розслідувань також можуть автоматично додаватися запити до AI, результати парсингу.
      Наприклад: розпочато розслідування “Витік даних про операцію Y” – аналітик робить серію кроків, AI допомагає, все це логічно збирається в одному місці. Потім за результатами можна сформувати звіт. - Верифікації (підтвердження/спростування): Цей журнал містить усі дії з перевірки подій. По суті, кожен запис – це: подія, попередній статус -> новий статус, хто змінив, коли, джерело доказу. - Адміністратор може переглянути цей журнал, щоб оцінити, чи не було помилкових підтверджень, або щоб відстежити ефективність аналітиків (наприклад, скільки подій перевірено ким). - Можна також зробити зведення: % підтверджених подій за добу, середній час від появи до підтвердження тощо. Ці KPI можуть бути корисними для внутрішнього аналізу.
      •	Аудит всіх дій: Окрім специфічних журналів, є загальний системний лог, де записано: входи/виходи користувачів, додавання джерел, оновлення налаштувань, збої (error log). Він потрібен для відлагодження і безпеки. Можливо, не всі ці дані доступні через інтерфейс (тільки для супер-адміна, можливо навіть напряму з серверу).
      Інтерфейси історії: - Історія інцидентів/розслідувань може мати власний UI: список, пошук, фільтри (по даті, по відповідальному аналітику). Обравши конкретний інцидент – можна побачити деталі: пов’язані події, прикріплені файли (якщо додавались, наприклад, знімки карт), підсумки. - Журнал верифікацій – у простішому вигляді таблиці. Можна фільтрувати по користувачу чи по статусу (подивитися всі спростовані випадки, наприклад). - Можливість експорту: можливо, адміністр захоче експортувати історичні дані (наприклад, всі події за місяць). Це можна зробити через CSV або формування звіту.
      Зберігання даних історії: - Таблиця events містить актуальні події. Для історичних (вже давно неактуальних) можна або зберігати їх там назавжди (простий шлях, просто мітка часу), або переносити в архівні таблиці при досягненні певного віку. Архівування може допомогти продуктивності, але додає складність. На етапі MVP всі події лишаються, а для performance можна додати індекси по часу. - Таблиця validations для підтверджень/спростувань (поле: event_id, old_status, new_status, user_id, timestamp, evidence_link). - Таблиця investigations (розслідування/інциденти): поля: id, title, description, status, created_at, closed_at, etc. Може бути ще зв’язкова таблиця investigation_events (event_id, investigation_id) для зв’язку з подіями. - Ємність: Оскільки система працює з великим потоком OSINT, за день можуть приходити десятки чи сотні повідомлень. За рік – десятки тисяч. PostgreSQL з цим обсягом впорається. Важливо мати індекси на полях часу і, можливо, гео (PostGIS) щоб швидко фільтрувати.
4. Нефункціональні вимоги
   4.1 Продуктивність та масштабованість
   •	Продуктивність: Система повинна працювати в режимі реального часу, тобто:
   •	Нове повідомлення від джерела має з’явитися на дашборді протягом секунд (ідеально 1-2 секунди після отримання). Це досягається асинхронною обробкою: парсер отримав – записав у БД – агент перевірив (0.5-1с) – через WebSocket розіслав.
   •	Інтерфейс користувача має реагувати швидко: фільтри, перемикання вкладок – <0.5 с, пошук – <1 с.
   •	Генерація звітів допускає більший час (кілька секунд до хвилини, залежно від даних), але користувача про це інформуємо лоадером.
   •	AI-відповіді: використання OpenAI API (GPT-4) може займати кілька секунд. Це прийнятно, але якщо можливо – краще паралелити: відправляти запит і показувати “AI думає…”. Якщо відповідь не приходить >30 с – видавати опцію повторити.
   •	Масштабованість користувачів: Оскільки продукт внутрішній, очікувана кількість одночасних користувачів невелика (наприклад, 10-50 аналітиків). Навіть якщо буде кілька сотень користувачів, сучасний стек (Go + Postgres) витримає це без проблем на середньому сервері. Але закладаємо можливість горизонтального масштабування backend:
   •	Статeless-сервер Go можна тиражувати на декілька примірників за балансувальником навантаження. Єдина умова – координація WebSocket. Для цього або використовуємо Redis Pub/Sub (що вже є) – всі інстанси підписані на один Redis, або sticky sessions (але краще перше).
   •	БД PostgreSQL може масштабуватись вертикально (додавання CPU/RAM). Якщо треба горизонтально – репліки лише для читання, або перехід на шардінг (малоймовірно).
   •	Redis сам по собі легко тримає тисячі підключень, тож для WebSocket broadcasts він підходить.
   •	Масштабованість даних:
   •	Джерела: система може трекати сотні джерел. Парсинг кожного щохвилини – потенційно навантаження. Треба оптимізувати частоти: для швидких джерел (Twitter/Telegram) – частіше, для сайтів – рідше.
   •	Події: якщо дуже багато подій, фронтенд стрічка не зможе показувати тисячі одночасно. Можна зробити підвантаження поступове (“Load more” при скролі вниз).
   •	Зберігання медіа: Якщо будемо зберігати зображення/відео, потрібне сховище (диск або об’єктне типу S3). У MVP – можна зберігати тільки посилання, не тягнути самі файли, щоб не роздувати.
   •	Відмовостійкість: Система повинна працювати 24/7. Тому:
   •	Регулярний backup БД (щодобовий, + WAL логи).
   •	Якщо падає AI-сервіс (наприклад, відсутній зв’язок з OpenAI) – система все одно працює, лише без автоматичної перевірки; користувачам показувати повідомлення “AI агент тимчасово недоступний”.
   •	Якщо падає парсер – можна передбачити гаряче перезавантаження (service supervisor) та нотифікацію адміну.
   •	WebSocket розрив – фронтенд має авто-реконнект.
   •	Сумісність:
   •	Браузери: таргетуємо сучасні (Chrome, Firefox, Safari, Edge) в актуальних версіях. IE не підтримується.
   •	Роздільна здатність: мінімум для десктопу 1366x768, бажано адаптивний до 1024x768. Мобільний не пріоритет, але планшети (iPad розмір) повинні нормально показувати.
   •	Мовна підтримка: Платформа наразі україномовна повністю (і всі тексти UI, і дані). В майбутньому може розглядатись багатомовність (англ для союзників), тому бажано UI тексти одразу винести в файл локалізації.
   4.2 Безпека
   Безпека системи AVESINT.AI – критичний аспект, зважаючи на військове призначення та чутливість даних. Основні заходи:
   •	Мережева безпека:
   •	Обов’язкове використання HTTPS для шифрування всього трафіку між клієнтом і сервером. Сертифікати – корпоративні або від довіреного центру, якщо буде зовнішній доступ.
   •	Сервер розміщується у захищеному сегменті. Якщо є розділення на фронтенд/бекенд/БД – всі зв’язки теж шифруються або в межах VPN.
   •	Можливе обмеження доступу за IP (наприклад, лише з військової мережі).
   •	Аутентифікація і авторизація: (розглянуто в 3.7) – 2FA, ролі, строгі паролі. Заборона спільних акаунтів – кожен користувач персональний, щоб відслідковувати дії.
   •	Рольовий доступ:
   •	Role-Based Access Control (RBAC) реалізовано на рівні API: кожен endpoint перевіряє роль і вирішує, чи дозволити операцію. Наприклад, POST/DELETE джерел – тільки Admin, підтвердження подій – Analyst або вище, перегляд звітів – Viewer теж може читати.
   •	В інтерфейсі приховуються кнопки, якщо роль не має права (але це лише UI, на сервері дублюється перевірка).
   •	Контроль активності: Session timeout 30 хв, як згадано – після цього користувача треба перелогінити. Також якщо браузер закрито – токен короткий, довго не живе.
   •	Журнали безпеки: Запис всіх входів, в т.ч. невдалих (з фіксацією IP, часу). Бажано інтегрувати оповіщення: 5 невдалих входів – повідомити адміністратору або заблокувати акаунт тимчасово (captcha/manual unlock).
   •	Валідація вхідних даних: Оскільки платформа тягне багато зовнішніх даних (OSINT), потрібна фільтрація:
   •	Якщо парсер отримує текст або заголовки з інтернету, треба очищати HTML, скрипти – щоб нічого шкідливого не відобразити. Використовувати white-list тегів якщо виводимо HTML або просто показувати як текст.
   •	Не завантажувати і не виконувати потенційно небезпечний контент на клієнті. Напр., якщо джерело кинуло посилання, не відкривати його автоматично.
   •	Санітизація даних перед зберіганням у БД (щоб уникнути SQL-ін’єкцій, хоч параметризовані запити в Go мають покрити це) і перед показом (XSS – Angular має вбудований захист, але за сторонній HTML треба дбати).
   •	Обмеження функцій AI: Використання LLM не повинно призвести до витоку даних. Правила:
   •	Модель не повинна отримувати інформацію, якою не володіє користувач. Тобто, якщо AI-агенту передаються частини бази даних для аналізу, вони повинні відповідати рівню доступу. В ідеалі, AI відповідає лише на те, що його явно попросили.
   •	Якщо використовуємо OpenAI API – розуміємо, що дані запиту можуть тимчасово зберігатися на стороні OpenAI. Тому критично секретні дані через API не пропускаємо. Можливі рішення: маскувати імена, координати (але тоді сенс губиться). Тому, або окремий контракт з OpenAI (де вони не зберігають, як обіцяють), або локальна модель.
   •	Заборона деяких запитів: агент не виконає те, що виходить за рамки OSINT (наприклад, “наведи ракету на координати” – не наш випадок, але такі речі варто фільтрувати).
   •	Захист від DDoS/злоумисників: Оскільки зовнішні користувачі відсутні, традиційний DDoS малоймовірний. Але з боку джерел: якщо ворог дізнається про нашу платформу, може спробувати засипати її фейковими даними через OSINT-канали. Тут допомагає система рейтингів: недостовірні джерела швидко відфільтруються. Також можна додати обмеження на кількість нових подій в одиницю часу від одного джерела, щоб спам-аккаунт не завалив стрічку (парсер може просто ігнорувати >N повідомлень за годину від невідомого джерела).
   •	Відповідність нормативам: Військові системи вимагають певних стандартів (ДСТУ з криптографії, можливо). Якщо потрібно, шифрування даних на диску – налаштування Transparent Data Encryption для PostgreSQL або повне шифрування дисків.
   •	Резервування і відновлення: Регулярні бекапи, а також план відновлення при збоях (Disaster Recovery). Для MVP, можливо, це ще не прописується, але в док-ції згадати варто, що таке планується.
   4.3 Технологічний стек
   Як вже зазначалось, обрано стек технологій, оптимізований під реальновременні веб-додатки з інтеграцією AI:
   •	Back-end: Go (Golang) – основна мова сервера. Фреймворк: можливо використаємо Echo або Gin для REST API, оскільки вони легкі і швидкі. Для WebSocket можна використати стандартну бібліотеку або Gorilla WebSocket. Concurrency (горутини) дозволить обслуговувати багато з’єднань одночасно і виконувати паралельні задачі (парсинг, AI).
   •	Front-end: Angular (актуальна версія 16). TypeScript + RxJS для реактивності. UI бібліотека: можливо Angular Material (для швидкої побудови форм, таблиць, і т.д.), плюс бібліотеки для карти (ngx-leaflet, або Google Maps компонент).
   •	Database: PostgreSQL (версія 13+). Використаємо можливості JSONB, якщо потрібно зберігати напівструктуровані дані (наприклад, оригінал повідомлення з соцмережі з усіма полями). PostGIS – для зберігання гео-координат і виконання запитів типу “в радіусі X км від точки”.
   •	Cache/Real-time: Redis. Модуль pub/sub – для пересилки повідомлень між екземплярами серверу. Також використаємо Redis як кеш для дорогих запитів (наприклад, результати частих AI-запитів або списки останніх новин).
   •	AI/ML:
   •	Для інтеграції з OpenAI API – використаємо офіційний SDK або просто HTTP виклики до їх endpoint (ChatCompletion).
   •	Для локальної LLM – можливий варіант: встановити модель (наприклад Llama 2 13B) і звертатися до неї через API, наприклад, використовуючи сервера HuggingFace Transformers або LocalAI. Проте це потребує виділеного GPU. Для MVP, швидше за все, будемо використовувати OpenAI GPT-4 (або GPT-3.5) для тестування можливостей.
   •	Можливо, Python-скрипти для специфічних AI задач (наприклад, якщо потрібно проаналізувати зображення – використаємо Python + OpenCV чи TensorFlow модель). Ці скрипти можуть викликатися з Go через CLI або gRPC.
   •	Parsing:
   •	Go має http-клієнт для запитів. Для RSS – можна використати бібліотеку feed чи rss.
   •	Якщо HTML парсинг – бібліотека goquery (jQuery style parsing).
   •	Telegram – є API (Telethon via Python, або Go lib tdlib).
   •	Twitter – зараз API обмежений, але можна RSS через Nitter, або якщо невеликі обсяги – використати сервіси типу snscrape (Python, OS).
   •	Альтернативно, парсинг можна доручити Python-воркеру, який інтегрується через Redis queue (наприклад, RQ or Celery in Python). Але це ускладнить архітектуру. Якщо Go впорається – краще все тримати в Go для простоти.
   •	DevOps:
   •	Контейнеризація: Docker-файли для усіх компонентів (web, api, db, redis). Можливість розгорнути на сервері чи Kubernetes.
   •	CI/CD: Налаштування пайплайна, щоб при оновленні коду автоматично збиралось і викочувалось (в межах закритої мережі можливо не зовсім continuous, а manual approval).
   •	Логування: використати структуроване логування (JSON), щоб потім аналізувати, і систему алертів (Prometheus + Grafana, Sentry для помилок – якщо доступно).
   •	Open-source компоненти: всі використані бібліотеки повинні мати ліцензії, сумісні з військовим використанням (в основному MIT, Apache – ок). Уникати AGPL компонентів в сервері (щоб не було вимог відкриття коду назовні).
   •	Інші інструменти:
   •	Якщо потрібно real-time перевести в мобільні повідомлення – можна інтегрувати Web Push або Signal/Telegram боти, але це поки не ставимо.
   •	Mapping: Leaflet (JS) + OSM tiles.
   •	Charting: для графіків в звітах або статистиці – бібліотека ngx-charts або D3.js.
5. Структура бази даних
   Нижче описано основні таблиці PostgreSQL, які використовуються у системі, та їх орієнтовні поля. Зв’язки між таблицями показують, як дані пов’язані (наприклад, подія прив’язана до джерела та, можливо, до інциденту).
   •	users – користувачі системи (аккаунти).
   •	user_id (PK, serial) – унікальний ідентифікатор.
   •	username (унікальний логін).
   •	password_hash – хеш пароля.
   •	full_name – ПІБ або позивний.
   •	role – роль/група (Admin/Analyst/Viewer).
   •	email, phone – контакти (для 2FA).
   •	created_at, last_login_at – часові мітки.
   •	is_active – прапор активності (можливо блокування).
   •	sources – джерела інформації.
   •	source_id (PK) – ідентифікатор.
   •	name – назва/короткий опис (наприклад, “Telegram: Інсайдер UA”).
   •	type – тип (enum: "Telegram", "Twitter", "Website", "RSS", "Official" ...).
   •	url – посилання або ідентифікатор (URL стрічки, @username, тощо).
   •	category – категорія (наприклад, "Official", "OSINT team", "Enemy propaganda").
   •	reliability – числовий рейтинг достовірності (FLOAT) цього джерела.
   •	last_checked_at – останній час парсингу.
   •	is_active – чи збираємо з нього дані.
   •	meta_info (JSONB) – додаткова інформація (наприклад, кількість підписників, якщо є).
   •	Зв’язки: Безпосередньо events->sources (можна у events зберігати source_id).
   •	events – події (інформаційні повідомлення).
   •	event_id (PK).
   •	title – короткий опис/заголовок (“Артобстріл у районі ...”).
   •	description – деталі (можливо текст з джерела або зведений опис).
   •	event_type – тип (якщо класифікуємо: “combat”, “movement”, “alert”, “other”).
   •	source_id – FK посилання на основне джерело, що повідомило.
   •	additional_sources (ARRAY або окрема таблиця event_sources) – інші джерела, що підтверджують (якщо є).
   •	occurred_at – час події (може відрізнятись від часу повідомлення, якщо у тексті вказано “сталося о 5:00” – тоді occurred_at = 5:00).
   •	reported_at – час отримання/створення запису (коли наш парсер додав).
   •	location – гео-координати (Point або два поля lat, lon). Тип PostGIS Geometry(Point, 4326).
   •	location_desc – текстовий опис місця (наприклад, "Бахмут, Донецька обл.").
   •	status – статус верифікації (enum: "pending", "confirmed", "disproved").
   •	credibility – коефіцієнт достовірності (FLOAT).
   •	validated_by – FK на users, хто останнім перевірив (NULL якщо ніхто).
   •	validated_at – час останньої перевірки.
   •	media_urls (ARRAY of text or JSON) – посилання на медіафайли (зображення/відео) або збережені файли.
   •	incident_id – FK на table incidents, якщо прив’язано до інциденту.
   •	incidents – інциденти/великі події.
   •	incident_id (PK).
   •	name – назва (“Бій за населений пункт X”).
   •	description – опис (може містити розвиток подій, якщо ведеться).
   •	start_time, end_time – часові рамки (end_time може бути NULL, якщо триває).
   •	status – активний/закритий.
   •	created_by – хто створив (user_id).
   •	(Події, що входять до інциденту – можна через поле event.incident_id або через зв’язкову таблицю якщо M2M).
   •	persons – особи, по яким зібрана інформація.
   •	person_id.
   •	name – ПІБ/псевдонім.
   •	affiliation – приналежність (наприклад, “Командування Південь ЗСУ” або “ГРУ РФ”).
   •	details (JSON) – довільні поля (дата народження, звання, і т.д.).
   •	reliability – опціонально, якщо є оцінка правдивості інформації про цю особу.
   •	last_updated – коли останній раз оновлювали досьє.
   •	(Можемо мати зв’язок person <-> events: якщо особа згадувалась у події, або person -> sources: якщо особа є джерелом/автором).
   •	vessels – судна/літальні апарати.
   •	vessel_id.
   •	name – ім’я або бортовий номер (наприклад, “фрегат Москва” або “RF-82038”).
   •	type – тип об’єкту (“ship”, “aircraft”, “vehicle” тощо).
   •	details (JSON) – характеристики (водотоннажність, модель літака і т.д.).
   •	last_known_position – гео-координати + час коли відомо.
   •	status – наприклад, “active”, “destroyed” якщо сталося.
   •	history (можливо JSON або окрема таблиця positions) – для трекінгу маршруту.
   •	ai_requests – журнал AI-запитів.
   •	request_id.
   •	user_id – хто запитав.
   •	query_text – текст запиту.
   •	response_text – відповідь (може зберігатися повністю, якщо не секретно, або хоча б для audit).
   •	request_type – тип ( “chat”, “verify_auto”, “report_gen” тощо).
   •	created_at, completed_at.
   •	status – виконано/помилка/тощо.
   •	validations – журнал верифікацій (підтверджень).
   •	validation_id.
   •	event_id.
   •	user_id – хто підтвердив/спростував.
   •	old_status, new_status – (наприклад, pending -> confirmed).
   •	evidence – текст або посилання на доказ.
   •	created_at.
   •	news_articles (опціонально) – якщо зберігати новини окремо:
   •	article_id, source_id, title, content, published_at, url, parsed_at, etc.
   •	Ці записи можуть пов’язуватись з events якщо треба (або бути джерелом для events).
   Вище — орієнтовна схема. У реальному проекті можна об’єднувати або розділяти таблиці для оптимізації. Наприклад, sources може включати як соцмережі, так і новинні сайти (через поле type). events можуть зберігати JSON оригінального повідомлення, щоб не втратити деталей.
   Зв’язки (ERD) коротко:
   Користувачі (1) -- (N) Верифікації.
   Джерела (1) -- (N) Події.
   Інцидент (1) -- (N) Події (подія може належати до 0 або 1 інциденту; можна M2M якщо треба).
   Подія (N) -- (M) Джерела (через event_sources якщо враховувати всі підтверджуючі джерела).
   Розслідування (інциденти) можуть бути пов’язані з особами або судами, якщо треба (наприклад, інцидент “знищення судна X” пов’язаний з vessel_id).
   AI-запити пов’язані з користувачем і можуть зберігати посилання на результати (якщо, наприклад, запит створив новий запис person чи event, то можна зберегти його ID).
   Приклад даних (для ілюстрації):
   Таблиця sources (витяг):
   source_id	name	type	reliability	last_checked_at
   1	Twitter: @ua_industry	Twitter	0.9	2025-10-14 14:00:00
   2	Telegram: Insider UA	Telegram	0.7	2025-10-14 13:59:00
   3	Website: Міноборони	Official	0.95	2025-10-14 13:50:00
   4	RSS: BBC News (World)	RSS	0.8	2025-10-14 13:45:00
   Таблиця events (витяг):
   event_id	title	source_id	occurred_at	location	status	credibility	incident_id
   101	Авіаудар по об'єкту в Одесі	3	2025-10-14 12:30:00	(46.48, 30.73)	confirmed	0.95	10
   102	Вибухи в районі аеродрому X	2	2025-10-14 13:10:00	(49.93, 36.28)	pending	0.6	11
   103	Переміщення техніки (колона)	2	2025-10-14 13:00:00	(48.05, 37.95)	disproved	0.1	NULL
   104	Повітряна тривога: Київщина	4	2025-10-14 13:55:00	(50.45, 30.52)	confirmed	0.99	NULL
   Таблиця validations (витяг):
   validation_id	event_id	user_id	old_status	new_status	evidence	created_at
   5001	102	7	pending	confirmed	https://mod.gov.ua/news/official_report	2025-10-14 13:20:00
   5002	103	5	pending	disproved	Аналіз фото: це подія 2022 року	2025-10-14 13:30:00
   Ці приклади показують, як зберігаються і пов’язуються дані.
6. UI-структура та навігація
   Інтерфейс користувача побудовано за принципом SPA (Single Page Application) з маршрутизацією між основними розділами. Ліворуч знаходиться бічна навігаційна панель (Sidebar) з переліком вкладок (як згадано в завданні): Огляд, Карта, Стрічка, Ревʼю (Адмін), Новини/Парсер, Налаштування. Верхня панель (header) відображає назву проекту "AVESINT.AI", іконки швидких дій (пошук, повідомлення, профіль користувача).
   Розглянемо кожну вкладку/сторінку:
   •	Огляд (Dashboard) – початкова сторінка після входу. Складається з віджетів:
   •	Стрічка останніх подій (може бути скорочена форма – топ-5, з посиланням “Переглянути всі ->” що веде на вкладку Стрічка).
   •	Мапа (також вбудована, можливо меншого розміру, або тепловая карта активності).
   •	Блок “Статистика за добу” – кількісні дані: скільки подій отримано, % підтверджено, активні джерела.
   •	Останні новини (теж кілька заголовків).
   •	Якщо роль Admin: віджет стану системи (наприклад, “Парсер: працює, 120 джерел; AI: 3 запити в черзі;”).
   •	Огляд – це більше зведення. Користувач може кастомізувати (в майбутньому): які блоки показувати.
   •	Карта – повноекранна карта з панеллю фільтрів. Ліва частина чи напівпрозорий оверлей містить чекбокси/фільтри. При кліку на маркер – спливашка з info і можливістю перейти до деталей.
   •	Можливо, справа є панель зі списком подій у вибраній області (синхронізований зі картою).
   •	Стрічка – список подій у хронологічному (чи анти-хронологічному) порядку. Вгорі фільтри (час, статус, тип). Кожен елемент – картка або рядок таблиці. Більш зручний – карточний вигляд: іконка типу, текст опису, метадані (час, локація, джерело). Клік відкриває модальне вікно або сторінку деталей події.
   •	Деталі події включають: повний опис, список джерел, медіа (якщо є), координати (з можливістю “показати на карті”), журнал верифікацій, коментарі AI (можливо, агент може прокоментувати).
   •	Прямо тут є кнопки “Підтвердити/Спростувати” якщо дозволено.
   •	Рев’ю (Адмін) – інтерфейс модерації та верифікації:
   •	Список непідтверджених подій (таблиця з колонками: час, заголовок, джерело, поточна достовірність, дій: підтвердити/спростувати).
   •	Список пропозицій AI: наприклад, AI може іноді автоматом підтвердити якщо дуже очевидно (але краще все через людину).
   •	Можливість призначити відповідального: якщо у команді декілька, адміністратор може розподілити (“цю подію перевіряє user X”).
   •	Також можливо тут список нових джерел, що очікують оцінки (якщо механізм додавання джерел з попередньою модерацією).
   •	Новини/Парсер – сторінка з переліком новинних статей, отриманих парсером:
   •	Ліва колонка: список заголовків з часом і джерелом.
   •	Права область: вміст вибраної новини (текст, картинка якщо є).
   •	Кнопка “Парсити зараз” зверху.
   •	Якщо новина релевантна, може бути кнопка “створити подію з цієї новини”.
   •	Налаштування (Settings) – доступно лише Адмінам, або частково всім (наприклад, змінити свій пароль).
   •	Особисті налаштування: профіль користувача – змінити пароль, увімкнути/відключити 2FA, налаштування сповіщень (наприклад, які push-нотифікації отримувати, якщо буде).
   •	Адмінналаштування: всі, перелічені в 3.6 – користувачі, системні параметри, AI, і т.д. Може бути вкладками або одна довга сторінка.
   •	Звіти (не було в списку навігації, але логічно, що має бути):
   •	Перегляд каталогу звітів (як згадано).
   •	Можливість створити новий звіт (кнопка “Новий звіт”).
   •	Редактор звіту: можна реалізувати простий rich text editor (вклеювати текст, вставляти перемінні – але для MVP можна навіть без WYSIWYG: просто текстові поля + генерувати).
   •	Якщо WYSIWYG важко, то хоча б генерація по шаблону і можливість скачати, а редагування offline.
   •	Пошук (Global Search) – хоча не виділено окремо, зазвичай у заголовку розміщують пошукову строку. Вона може шукати по всьому: подіях, джерелах, особах. Це швидко привести до потрібної інформації. Результати – у випадаючому списку або окрема сторінка з категоризованим виводом (“Збіги серед подій:...; серед джерел: ...”).
   Модальні вікна та діалоги: - Деталі події – може бути як діалог. - Підтвердження/спростування – при натисканні відкривається модал з полем “Джерело підтвердження” і ОК/Cancel. - Додавання джерела – форма може бути модальною. - Редагування профілю – теж діалог. - Попередження про вихід по таймауту – спливаюче діалогове. - Підтвердження видалення – стандартне.
   Використання стилів: З огляду на військову тематику, інтерфейс бажано зробити у стриманих тонах, темна тема (сіро-синя гама) може бути за замовчуванням (зручніше для роботи ночами і в приміщеннях командних). Лого проекту AVESINT.AI можна розробити (наприклад, стилізоване зображення хижого птаха, що символізує “Око, що все бачить” чи щось таке). Але це необов’язково на етапі ТЗ.
   Адаптивність: На широких екранах одночасно видно і карту, і стрічку (наприклад, 2 колонки). На середніх – вкладки перемикаються. На мобільних (якщо хтось буде з телефона) – навігація прихована в бургер-меню, карта – фулскрін, стрічка – скролл.
7. Пояснення механік реалізації ключових компонентів
   У цьому розділі підсумуємо найбільш складні або важливі механізми системи та пояснимо, як вони працюватимуть “під капотом”:
   7.1 Валідація джерел
   Валідація джерел – процес оцінки надійності нового або існуючого джерела. Реалізація: - Первинна валідація при додаванні: Як описувалось (3.4), при додаванні джерела AI автоматично переглядає його останні пости. Використовуються критерії: - Чи публікує джерело оригінальний контент, чи перепощує інших? (Первинне джерело цінніше, але інколи перепости офіційного – теж непогано). - Історія створення: якщо акаунту 1 день – насторожує. - Ознаки ботоповодження: наприклад, у Twitter – багато постів за короткий час, без взаємодії. - Тональність: якщо канал явна пропаганда (суцільні емоційні вислови, образи) – знизити рейтинг.
   Результат – початковий рейтинг. Якщо сумніви, можна вимагати ручної перевірки адміном: він подивиться зміст постів і підтвердить включення. - Постійна переоцінка: Рейтинг джерела не статичний. Він автоматично перераховується після кожної значущої події: - Якщо від джерела надійшла інформація і вона підтвердилась – репутація росте. - Якщо спростована – суттєво падає. - В формулі можна застосувати затухання: недавні події впливають більше.
   Наприклад, джерело опублікувало 10 новин, 8 підтвердились, 2 ні: базово 0.8. Але якщо 2 неправильні були останніми – можна тимчасово опустити рейтинг сильніше (припускаючи, що його могли скомпрометувати). - Модерація джерел: Адміністратор періодично переглядає список джерел. Якщо якийсь має дуже низький рейтинг (наприклад <0.3) і приносить тільки шум – приймає рішення відключити його (або позначити “ненадійне”). Можливо, не видаляючи, а саме відключає збір (щоб історія лишилась, але нові не приходили). - Використання зовнішніх даних: Для критичних джерел можна залучати інформацію ззовні. Наприклад, якщо це медіа – подивитись, чи не згадувались вони в списках фейкоробів. Є проекти, які відслідковують пропагандистські сайти. Інтегрувавши такі списки, можна автоматично помічати джерело як “blacklisted” і попереджати аналітиків. - Tagging: Джерела можуть мати теги: “trusted”, “doubtful”, “official”. Ці позначки допомагають AI і людям. Наприклад, усі “official” (державні сайти) апріорі високий рейтинг, навіть якщо мало даних. А “enemy propaganda” – низький, навіть якщо не спростовано (бо може не було можливості). - Прозорість для користувачів: В аналітиці джерела користувач може бачити, чому такий рейтинг. Можна навіть застосувати відомі підходи розвідки: - Оцінка надійності джерела: A (цілком надійне) – F (ненадійне)[4]. - Оцінка достовірності інформації: 1 (підтверджено багатьма) – 5 (не можна перевірити) – 6 (явно неправдиве). - У системі ці два аспекти злиті в коефіцієнт, але при бажанні можна відображати їх окремо (наприклад, Джерело: B – зазвичай надійне, Інформація: 2 – дуже ймовірно).
   Так користувачі зрозуміють, що стоїть за цифрою 0.7 (умовно, “B2” за шкалою – джерело зазвичай достовірне, інформація має ознаки правдивої, але не підтверджена офіційно)[5].
   7.2 Аналітика достовірності (коефіцієнт цілісності)
   Аналітика достовірності – це і про окремі події (що вже розглянуто), і про глобальний аналіз: - Побудова довіри: З часом у системі накопичиться статистика: які джерела більш надійні, які теми часто викликають фейки (наприклад, може бути, що 90% “новин” про певного політика – фейки, тоді ця тема сама по собі червоний прапор). - Виявлення шаблонів: Можна доручити AI проаналізувати масив даних: знайти взаємозв’язки між джерелами (чи не поширюють вони однакові фейки одночасно – значить, можливий спільний координатор). Або проаналізувати часові тренди (наприклад, в який час доби найбільше неправдивих вкидень – можливо, це відповідає медіа-активності ворога). - Integrity Score для всієї інформації: Можна визначити показник “інформаційної цілісності” за період – умовно, % достовірної інформації в загальному потоці. Якщо він падає – сигнал, що поширюється багато дезінформації. - UX аналітика: У UI можна додати сторінку “Аналітика OSINT” де графіки: - Розподіл джерел за надійністю (гістограма). - Кількість спростованих повідомлень за тиждень. - ТОП-5 джерел за кількістю фейків і ТОП-5 найнадійніших. - Візуалізація мережі джерел (якщо відомі перехресні посилання: хто кого цитує). - Автоматична модерація: Якщо якийсь новий фейк швидко розлетівся по 10 джерелам (може, ботоферма) – система це помітить і зможе відзначити ці події групою: “можлива інформаційна атака”. Для цього AI дивиться, що декілька джерел одночасно публікують одне й те саме з однаковим текстом – ймовірно скоординована діяльність[8]. У такому випадку достовірність кожного окремо може була б середня, але об’єднання такої інформації без незалежних підтверджень – привід знизити достовірність усім одразу, поки не з’явиться справжній доказ. - User feedback: Військові аналітики користуються системою і фактично теж “мітять” дані (через підтвердження). Їхній досвід – частина аналітики. Наприклад, якщо конкретний користувач багато що спростовує, можливо варто переглянути звідки він бере інформацію. Але це радше для внутрішнього контролю, не для автоматизації. - Експортування знань: Дані про достовірність можуть бути корисні ширше (наприклад, передати в Центр стратегічних комунікацій інфу про викриті фейки). Але то вже поза системою.
   7.3 AI-запити (інтеграція LLM)
   Реалізація AI-запитів складається з декількох рівнів: - Інтерфейс користувача: Чатбот чи форма, де можна ввести запит. Коли користувач відправляє: - Фронтенд може додатково вказати параметри (наприклад, тип запиту “особа” якщо натиснуто спеціальну кнопку перед цим). - Кнопка “Виконати”, після чого з’являється елемент “виконується…”. - Передача на сервер: Бекенд отримує запит. Є окремий контролер (endpoint) /ai/query. - Він створює запис в таблиці ai_requests (status=running). - Далі або синхронно, або асинхронно обробляє. Краще асинхронно: ставить завдання в чергу (можна у пам’яті або Redis). Чому? Бо LLM-відповідь може йти 5-30 секунд. - Клієнту одразу відповідає “прийнято, request_id = X”. А фронт слухає по WebSocket/полінгу результат. - Виконання запиту: Окремий воркер (може бути запущений горутиною або окрема мікросервіс) обробляє чергу: 1. Аналізує текст запиту – класифікує, що хоче користувач. Можна мати простий набір правил або модель: якщо містить слово “сформуй звіт” – очевидно, генерація звіту; якщо “знайди інформацію про” – пошук особи чи об’єкта; якщо “перевір чи правда що” – фактчек. Для MVP можна почати з правил/ключових слів. 2. Залежно від типу, викликає відповідні допоміжні функції: - Пошук в БД (наприклад, імені особи). Якщо знайдено – зібрати дані та передати в prompt LLM: “На основі внутрішніх даних: ... Сформулюй відповідь”. - Пошук в інтернеті: можливо, інтеграція з сторонніми API. Або якщо не робити живий веб-пошук, можна використати проіндексований корпус (але для OSINT потрібні свіжі дані, так що швидше прямі запити). - Виклик спеціалізованих AI-моделей: розпізнавання облич, класифікація зображень. Наприклад, якщо запит “що зображено на фото” і прикріплено фото – може викликатись модель комп’ютерного зору. 3. Формування prompt для LLM: - Має інструкцію (system message) з контекстом, наприклад: “Ти – OSINT-помічник. Відповідай стисло і точно, посилаючись тільки на перевірені дані.”. - Додає знайдену інформацію (з БД або зовні) у prompt, позначивши її як контекст. - Включає користувацький запит. 4. Надсилає до моделі (OpenAI). Отримує відповідь. 5. Може пост-обробити відповідь: додати форматування Markdown, замінити посилання-шаблони на реальні посилання, цензурувати якщо щось зайве. 6. Записує відповідь у ai_requests (response_text, status=completed). 7. Нотифікує фронтенд: або через WebSocket подію типу “ai_response” з request_id, або клієнт сам опитує /ai/status?id=X. - Відображення відповіді: На фронті користувач бачить відповідь у чаті або окремому вікні. Якщо потрібно, може задати уточнення – тоді новий запит з посиланням на попередній (можна контекст зберегти). - Приклад взаємодії: - Запит: “Перевір, чи правда, що вчора знищено танкову колону під Ізюмом.” - Дії AI: - Знайти в БД події за вчора з тегом “танкова колона, Ізюм” – якщо є, ймовірно знайде, що була подія з достовірністю 0.2 (фейкова). - Знайти у новинах – можливо нічого. - Вихід: “За наявною інформацією, підтверджень знищення танкової колони під Ізюмом немає; була інформація від сумнівного джерела, яку спростовано[1]. Отже, це скоріше за все неправда.” (В ідеалі додасть посилання на спростування).
   •	Запит: “Які кораблі ЧФ РФ наразі в Чорному морі?”
   o	AI звернеться до таблиці vessels, вибере активні з фільтром location=Black Sea. Якщо є інтеграція з зовнішнім (наприклад, останній зведення від ВМС про склад кораблів) – теж використає.
   o	Згенерує список: “Станом на сьогодні в Чорному морі: 2 фрегати (Буревісник, Шторм), 3 корвети…, 1 підводний човен. (Дані за станом на 14.10.2025)”.
   •	Обробка помилок: Якщо AI не впорався (таймаут, або не знає відповіді):
   •	Відповідь типу: “Немає достатньо даних для впевненої відповіді.”
   •	Лог помилки зберегти (наприклад, OpenAI вернула error).
   •	Можна спробувати fallback на простіший маршрут (наприклад, GPT-3.5, якщо 4 недоступний).
   •	Обмеження: Щоб запобігти зловживанням, можна встановити:
   •	Ліміт довжини запиту (наприклад, 500 символів).
   •	Ліміт частоти (не більше 5 запитів за хвилину з акаунта).
   •	Можливість для адміністратору переглядати журнал ai_requests – що питають (раптом хтось почне не за темою витрачати ресурси).
   •	Наведення довідок: Якщо AI використав дані з нашої БД або звіту, добре б дати посилання в тексті відповіді (як наш чат-бот зараз з джерелами). У внутрішній системі теж це можна: наприклад, “... спростовано офіційно[1]” – і при наведенні показати, що це за джерело (посилання на запис чи зовнішній ресурс). Реалізувати це можна Markdown синтаксисом і збереженням мапи для ідентифікаторів джерел.
   7.4 Парсинг даних (новини, соцмережі)
   Механізм парсингу – це бекенд-сервіс, який періодично або вручну збирає дані з зовнішніх джерел:
   •	Новини (RSS/сайти):
   •	Якщо є RSS: простий cron job щоп’ятнадцять хвилин – пройдися по списку news_sources, для кожного витягни feed, розбери item-и. Нові (за GUID або посиланням, яких ще нема в БД) – додай в таблицю news_articles.
   •	Якщо немає RSS: використовуємо HTTP GET HTML, парсимо через правила (наприклад, сайт XYZ – шукаємо в HTML елементи <article> чи <div class="news-item">). Для кожного джерела можливо треба налаштувати окремий парсер (регулярки або CSS-селектори).
   •	Після отримання статті – бажано виділити з неї ключову інформацію:
   o	Час, місце, сутності (імена, техніка). Тут може допомогти NLP: запустити просту модель NER (Named Entity Recognition) або regular expressions для локацій.
   o	Якщо знайдено щось, що схоже на подію (наприклад, “стався вибух у ... о ...”) – сформувати event.
   o	Можна поставити прапор, наприклад: у таблиці news_articles поле event_id – якщо створено подію з цієї новини. Тоді, якщо пізніше буде підтверджено, ми знаємо, що ця новина правдива.
   o	Новини також можуть долучатися до інцидентів (наприклад, стаття “Підсумки боїв за тиждень” – вона не подія, але корисна. Це може бути просто інформація без гео).
   •	Web scraping caution: Поважаємо robots.txt (але для OSINT, можливо, доведеться ігнорувати). Також не перевантажуємо сайти (можна ставити паузи, кешувати відповідь).
   •	Соцмережі (Twitter, Telegram):
   •	Twitter/X: Офіційно API зараз урізаний. Можливі шляхи:
   o	Через RSS-посередники (деякі сервіси генерують RSS стрічки Twitter, хоча з закриттям API може й вони полягли).
   o	Через скрипти парсери: напр. snscrape – Python утиліта, яка без API отримує твіттер фід (використовуючи неофіційні методи). Її можна запускати з Go (subprocess) і отримувати JSON.
   o	Через сервіси типу nitter (дзеркала Twitter) – можна робити GET https://nitter.net/user/rss.
   o	MVP-спосіб: включити лише ті Twitter-акаунти, які мають дубль в Telegram або на сайтах (багато офіційних осіб дублюють).
   •	Telegram:
   o	Якщо це публічний канал, можна отримувати через бот API (потребує бот-акаунт доданий в канали? або через клієнт-API). Існують бібліотеки (tdlib, Telethon) – але їх інтеграція дещо громіздка.
   o	Інший шлях: є сервіси-агрегатори (tgstat, telegramic) або знову ж через RSS-ботів. Наприклад, бот @FeedReaderBot дозволяє читати канал як RSS – але для автоматики непевно.
   o	Можна обмежитися кількома ключовими Telegram-каналами, які мають веб-інтерфейс (t.me/username – там останні ~10 постів можна HTML витягти).
   o	Кожен пост Телеграму – якщо є текст, беремо його. Якщо лише зображення – можна використати розпізнавання тексту з зображення (OCR) якщо важливо.
   •	Facebook/Instagram: менш критично, бо військова тематика там мало, і їх складно парсити (потрібен логін).
   •	YouTube: якщо є джерела (канали новин) – можна моніторити нові відео через YouTube API або сторонній RSS (YouTube надає RSS для каналів).
   •	Обробка багатоязиковості: Джерела можуть бути українські, англійські, російські. Для аналізу тексту AI може перекладати при потребі (наприклад, щоб вирівняти і потім порівняти). Але здебільшого аналітики читають і так.
   •	Парсинг тривог: Повітряні тривоги можливо не через парсинг сайту, а через офіційний веб-сокет (є така система "повітряна тривога" – може бути API). Або через канали в телеграм (є канал, який постить “Тривога: Київська”). Їх можна обробити окремо та відобразити.
   •	Структура коду парсерів:
   •	Можна зробити окремий модуль collector зі складовими: collector/rss.go, collector/telegram.go і т.д.
   •	Використовувати context.Background() і time.Ticker для періодичного виклику. Або cron, або запускати парсинг через системний планувальник (Linux cron hitting an endpoint).
   •	Якщо парсер знаходить щось нове – він сам може відразу створити event або запише news_article і потім окремий код вирішить.
   •	Взаємодія з AI при парсингу: Можна залучати AI, щоб класифікувати новину чи витягнути з неї структуру (назви осіб, місць). Але це виклик на кожну новину – дорого. Можна для MVP зробити прості регулярні вирази: пошук “в районі (\w+)” – знаходити місце, тощо. Далі, коли обсяг виросте, навчити свою модель або використовувати GPT на вимогу (наприклад, для критичних новин).
   •	Логування і контроль: Парсер повинен вести лог: що пройшло успішно, де помилки (наприклад, сайт недоступний). В адмін-інтерфейсі це відображається, щоб знати, якщо якісь джерела довго не оновлюються.
8. Реалізація та етапи впровадження (Roadmap)
   Розробку AVESINT.AI пропонується здійснити ітеративно, виділивши MVP (мінімально життєздатний продукт) за ~1 місяць та наступні фази для розширення функціоналу. Нижче наведено план реалізації з пріоритетами:
   8.1 Етап 1: MVP (1 місяць)
   Мета: Поставити основний кістяк системи, що дозволяє збирати події у реальному часі, відображати їх на карті та стрічці, а також виконувати базову верифікацію і звітність. AI-функціонал – у базовому вигляді (авто-оцінка достовірності, прості відповіді на запити).
   Обсяг MVP: 1. Back-end базовий API: Створення структур БД, REST API для подій, джерел, користувачів. Реалізація авторизації (JWT). Налаштувати WebSocket канал для оновлень подій. 2. Front-end основа: Створити проект Angular, сторінки логіну, головного дашборду з простим віджетом (наприклад, “Ласкаво просимо, [Name]” і статистика 0). Налаштувати Angular Router для вкладок. 3. Парсинг кількох джерел: Налаштувати парсер для 3-5 ключових джерел (напр., офіційний сайт МОУ через RSS, Telegram-канал ЗСУ через HTML, новини Укрінформ через RSS). Регулярно отримувати події звідти і складати в БД. 4. Реальний час: Налагодити механізм WebSocket – коли додається подія, передавати клієнту. Відобразити на фронті (хоча б у консолі спершу, потім у UI). 5. Стрічка подій (UI): Реалізувати компонент списку подій: простий список з основною інформацією. Можна без стилізації спочатку, головне – дані з API. Реалізувати фільтр за статусом (pending/confirmed). 6. Мапа (UI): Інтегрувати карту (Leaflet). Виводити маркери подій (можливо, статична іконка для всіх на MVP). Клік по маркеру показує назву події. 7. User management: Реалізувати найнеобхідніше – логін, логаут, примусову перевірку токену кожні 30 хв (можна спростити, просто токен 30 хв без refresh на MVP). Додати 2-3 користувачів вручну в БД. 8. Верифікація події (UI+API): Додати в API ендпоінт для зміни статусу події. На фронті – кнопку “Confirm”/“Disprove” в деталях події (поки без посилання на джерело, або з текстовим коментарем). Змінений статус зберігається, надсилається всім клієнтам. Коефіцієнт достовірності – можна для MVP просто виставляти 1.0 або 0.0 при підтвердженні/спростуванні. 9. AI інтеграція (мінімум): - Модуль auto-verify: після додавання події, виконати просту перевірку – наприклад, якщо джерело в списку “надійних” -> credibility=0.7, інакше 0.5. (Це поки що без реального AI, але логіка). - Підготувати інтеграцію з OpenAI: зробити один тестовий endpoint, що на запит “summarize text: ...” повертає відповідь. Цей endpoint використати, наприклад, для генерації короткого опису події або відповіді на простий запит користувача. - Chat UI: додати вкладку або секцію, де можна ввести питання до AI і отримати відповідь (через OpenAI API). Наприклад, “Як працює ця система?” – GPT відповідає (демо цінності). 10. Прототип звіту: Реалізувати генерацію PDF для однієї простої ситуації: - Натиск “Експорт в PDF” на деталях події – згенерувати PDF з назвою, описом, часом. - Можна використати просту бібліотеку і текст. - Без кастомного тексту, просто як факт – щоб перевірити працездатність механізму.
   Тестування MVP: На кінці місяця провести внутрішнє тестування: створити штучно кілька подій, пройтись сценаріями (парсер додає, AI оцінює, користувач підтверджує, карта оновлюється, PDF генерується). Залучити кінцевих користувачів (якщо є можливість) для фідбеку.
   8.2 Етап 2: Розширення функціоналу (2-й місяць)
   Мета: Додавання більш просунутих можливостей, які не встигли в MVP, та полірування існуючих: - Повноцінна рольова модель: інтерфейси для створення/редагування користувачів, механізм refresh token, повне 2FA. - Додаткові джерела: підключити більше каналів Telegram і Twitter (можливо, з допоміжними скриптами). - Аналітика джерел UI: сторінка зі списком джерел, рейтинги, графіки. - Автоматична перевірка AI: інтегрувати реальні перевірки – наприклад, використовувати OpenAI щоб знайти згадки події в інтернеті (через їх Plugins/WebBrowsing якщо доступно, або custom integration). - Звіти генерація: зробити шаблон добового звіту. Можливо, інтегрувати генерацію DOCX (бібліотека, наприклад, docx4j). Додати UI для перегляду/редагування перед експортом (може, текстові поля або простий Markdown редактор). - UI/UX покращення: стилізувати інтерфейс, додати індикатори завантаження, повідомлення про помилки (напр., якщо парсер недоступний – показати у UI). - Журнали/аудит: сторінка для admin з логами підтверджень, можливістю експорту CSV. - Безпека: Впровадити rate limit, account lockout при підборі паролю, CSRF-токени для форм (Angular це може сам, якщо JWT – то не дуже потрібно CSRF). - Оптимізація продуктивності: додати необхідні індекси до БД (наприклад, index на events.occurred_at, на events.location з GIST для гео), налаштувати caching на фронті (наприклад, зберігати отримані довідники в memory). - Тестування: написати набір unit-тестів для критичних частин (парсер, AI відповіді), e2e-тести для UI сценаріїв.
   8.3 Етап 3: Advanced Features (3-й місяць і далі)
   Мета: Підвищення інтелектуальності системи та підготовка до бойового використання на повну: - AI Локальний: Розгорнути локальну LLM модель на сервері (за умови наявності GPU). Провести навчання або fine-tuning на основі зібраних даних (наприклад, щоб AI розумів військову термінологію українською). - Візуальна аналітика: Впровадити обробку зображень (наприклад, автоматичне визначення техніки на фото, геолокація по фото – можливо інтеграція з tools типу Img2Geo). - Шари карти: Додати малювання на карті (наприклад, вручну позначити зону боїв), можливо імпорт даних розвідки (якщо дадуть). - Мобільний додаток: Якщо потрібно, розробити спрощену версію для смартфонів (аналітику в полі). - Взаємодія з іншими системами: Експорт даних у формати, які можна підвантажувати в GIS системи або передавати старшим штабам. Або API для інтеграції (наприклад, надати API союзникам для отримання підтвердженої інформації). - Удосконалення рейтингових алгоритмів: застосування машинного навчання на історичних даних: навчити модель, яка за ознаками (джерело, ключові слова, час) прогнозує достовірність. Це допоможе AI агенту точніше оцінювати нові події.
   Пріоритети реалізації: У першу чергу закриваємо ті речі, без яких система не буде цінною для користувача: 1. Основний потік подій (Real-time feed) – високий пріоритет, це серце системи. 2. Мапа – високий, бо візуалізація ключова для сприйняття обстановки. 3. Верифікація (manual + auto) – високий, щоб відрізняти шум від цінного. 4. User Auth & Security – високий, без цього не можна експлуатувати. 5. AI базові функції – середній пріоритет в MVP (можна почати з мінімуму), але обов’язково високий пріоритет на наступних етапах, бо це фішка платформи. 6. Звіти – середній пріоритет: на рівні MVP достатньо мінімальної підтримки, але для реального використання (коли командування попросить зведення) – високий на етапі 2. 7. Джерела/Аналітика джерел – середній для MVP (можна вручну додати 5 джерел і ок), але високий на етапі 2, коли система масштабується. 8. Адмін-панель – середній, в MVP можна дещо робити через БД напряму, але до розгортання в бойових умовах потрібен зручний адмін UI. 9. Полірування UI/UX – низький в MVP (функціональність важливіша за красу), але середній на етапі 2 (щоб користувачі радо користувались, особливо хто не технічний).
   Оцінка ресурсів: Команда для такого проекту бажано 3-5 розробників (1-2 фронт, 1-2 бек, 1 AI/data scientist), + 1 QA. За місяць MVP – напружено, але можливо при високій продуктивності, або якщо частково використовувати готові компоненти.
   Ризики та пом’якшення: - Надійність AI: GPT-4 API може інколи давати збій або несистематичні відповіді. Треба тестувати під наші сценарії, можливо доведеться настроювати промпти. - Зміни в джерелах: Джерела можуть змінювати формат (HTML), тому парсери треба підтримувати, закласти гнучкість або швидку можливість правки (наприклад, винести шаблони в конфіг). - Безпека: Слід проводити аудит коду (особливо зовнішнього ввод, weblinks), щоб не стати жертвою хакерів. - Навчання персоналу: Перед впровадженням треба буде навчити аналітиків користуватись новим інструментом. Платформа інтуїтивна, але все ж провести інструктаж.
9. Висновок
   Проект AVESINT.AI покликаний стати потужним інструментом військової розвідки на основі відкритих даних, що поєднує технології реального часу, штучного інтелекту та експертний аналіз. Ретельно продумана архітектура і функціонал дозволять оперативно отримувати важливу інформацію, відсіювати дезінформацію та підтримувати прийняття рішень командування на основі достовірних даних. Запропоноване технічне рішення охоплює всі необхідні аспекти – від збору та зберігання даних, до їх аналізу, верифікації, зручного представлення і забезпечення безпеки.
   Протягом першого місяця (MVP) буде реалізовано базові можливості платформи, після чого шляхом поступових ітерацій система набуде повного передбаченого функціоналу. Пріоритет надається критично важливим можливостям (моніторинг подій, карта, верифікація), тоді як другорядні (детальна аналітика, звіти) будуть доопрацьовані відразу після MVP. Такий підхід забезпечить якнайшвидше розгортання мінімально працездатної версії для тестування в бойових умовах та збір відгуків, з подальшим вдосконаленням.
   Примітка: Усі конфігурації (ключі доступу, адреси API) будуть розміщені у захищених файлах налаштувань. В кінці ТЗ можна додати додатки: наприклад, приклад JSON відповіді API, приклад макету інтерфейсу, ER-діаграму. Ці деталі можуть бути розроблені на основі цього ТЗ під час реалізації.
   Таким чином, документ надав цілісне бачення проекту AVESINT.AI. Команда розробки може використовувати його як дорожню карту, впевнившись, що всі вимоги враховано. За підсумками місячної розробки очікується демонстрація MVP перед замовником (військовим підрозділом) та подальше погодження наступних кроків.

